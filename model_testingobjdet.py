# -*- coding: utf-8 -*-
"""model_testingOBJDET.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vf83AYs5xTAcsgv60neEXnGte6_vrKxu

This entire notebook is useful to note which problems I encountered in terms of preparing the .xml files for generating TFRecords (binary form data). However, the entire notebook was made when my dataset was faulty. I had neglected the option of annotating other objects in my images, so only houses were annotated in 'house' images, and trees in the background were left without bounding boxes. This lack of quality would confuse the model's accuracy.

After I had fixed a much smaller dataset of images, and made sure to label each object I wanted to detect, the model was much more accurate.
"""

!pip install wget

import os
import glob
import wget
import imghdr
from PIL import Image
from pathlib import Path
import matplotlib.pyplot as plt
import xml.etree.ElementTree as ET

"""The first model I would like to try is the 'SSD MobileNet V2 FPNLite 320x320' model, which offers a computing speed of 22 milliseconds per frame, and an average precision of 22.2 units.

(Precision and recall are two values used to measure the validity of the model. They will be explained below when I train these models.)
"""

CUSTOM_MODEL_NAME = 'topdown'
PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'
PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'
TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'
LABEL_MAP_NAME = 'label_map.pbtxt'

"""The second model I would like to try offers a computing speed of 39 milliseconds per frame, and an average precision of 28.2 units. This model resizes the units to a larger size, 640 x 640. This model would enable the model to capture more features, so it would be worth testing out. However, overfitting could be an issue here, if a large model is asked to learn more features. Therefore, the training steps will be kept at around 10,000 - 12,500."""

CUSTOM_MODEL_NAME = 'thirdtry640x640'
PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'
PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'
TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'
LABEL_MAP_NAME = 'label_map.pbtxt'

paths = {
    'WORKSPACE_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace'),
    'SCRIPTS_PATH': os.path.join('/content/drive/MyDrive/Tensorflow','scripts'),
    'APIMODEL_PATH': os.path.join('/content/drive/MyDrive/Tensorflow','models'),
    'ANNOTATION_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','annotations'),
    'IMAGE_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','images'),
    'MODEL_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models'),
    'PRETRAINED_MODEL_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','pre-trained-models'),
    'CHECKPOINT_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),
    'OUTPUT_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),
    'TFJS_PATH':os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),
    'TFLITE_PATH':os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),
    'PROTOC_PATH':os.path.join('/content/drive/MyDrive/Tensorflow','protoc')
 }

files = {
    'PIPELINE_CONFIG':os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),
    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),
    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)
}

for path in paths.values():
    os.makedirs(path, exist_ok=True)
    print(f"Created directory: {path}")

"""# Image Moving and Preparation"""

folder_path = '/content/drive/MyDrive/Tensorflow/workspace/images/test/TREES_test'

# List all files in the folder
file_list = os.listdir(folder_path)

"""Naming each filename according to its class:"""

# Iterate through each file and rename with the prefix
for filename in file_list:
    if not filename.startswith('tree'):
        new_filename = 'tree_' + filename
        original_file_path = os.path.join(folder_path, filename)
        new_file_path = os.path.join(folder_path, new_filename)
        os.rename(original_file_path, new_file_path)
        #print(f'Renamed: {filename} -> {new_filename}')

"""I need to update the .xml files for each image now:"""

base_dir = '/content/drive/MyDrive/Tensorflow/workspace/images'
subfolders = ['train', 'test']

for subfolder in subfolders:
    subfolder_path = os.path.join(base_dir, subfolder)
    #for root, dirs, files in os.walk(subfolder_path):
    for xml_file in glob.glob(subfolder_path + '/*.xml'):
          tree = ET.parse(xml_file)
          root = tree.getroot()

          # Extract the filename from the XML file
          xml_filename = os.path.basename(xml_file).replace('.xml', '') + '.jpg'

          # Update the <filename> element
          filename_element = root.find('filename')
          if filename_element is not None:
            filename_element.text = xml_filename

          path_element = root.find('path')
          if path_element is not None:
            new_path = os.path.join(subfolder, xml_filename)
            path_element.text = new_path

          # Save the changes back to the XML file
          tree.write(xml_file)
          #print(f"Updated {xml_file}")

for subfolder in subfolders:
    subfolder_path = os.path.join(base_dir, subfolder)
    for xml_file in glob.glob(subfolder_path + '/*.xml'):
        tree = ET.parse(xml_file)
        root = tree.getroot()

        # Extract the filename from the XML file
        xml_filename = os.path.basename(xml_file).replace('.xml', '')

        # Find the corresponding image file
        image_extensions = ['.jpg', '.jpeg', '.png', '.jfif']  # Add other possible extensions
        image_file = None
        for ext in image_extensions:
            image_path = os.path.join(subfolder_path, xml_filename + ext)
            if os.path.exists(image_path):
                image_file = xml_filename + ext
                break

        if image_file is not None:
            # Update the <filename> element
            filename_element = root.find('filename')
            if filename_element is not None:
                filename_element.text = image_file

            # Update the <path> element
            path_element = root.find('path')
            if path_element is not None:
                new_path = os.path.join(subfolder, image_file)
                path_element.text = new_path

            # Save the changes back to the XML file
            tree.write(xml_file)

"""Extracting the images into the 'train', and 'test' folders"""

source_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train/TREES_train'
destination_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train'

for filename in os.listdir(source_folder):
  source_path = os.path.join(source_folder, filename)
  destination_path = os.path.join(destination_folder, filename)

  # Move the file to the destination folder
  shutil.move(source_path, destination_path)

print("Files moved successfully!")

"""# Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD

only need to do this ONCE
"""

if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):
    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}

!apt-get install protobuf-compiler
!cd /content/drive/MyDrive/Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .

"""Run the above code at the start of each runtime, then run the following cell to import all the necessary modules in the environment. Colab creates a new environment automatically, but actions in Command Prompt will need a new environment created for this task."""

VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')
# Verify Installation
!python {VERIFICATION_SCRIPT}

import object_detection

!pip list

"""This cell downloads the pre-trained model you named as PRETRAINED_MODEL_NAME where PRETRAINED_MODEL_URL is available to pick from the list at https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"""

!wget {PRETRAINED_MODEL_URL}
!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}
#!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}

PRETRAINED_MODEL_NAME = '/content/drive/MyDrive/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'

#!wget {PRETRAINED_MODEL_URL}
#!mv {PRETRAINED_MODEL_NAME} {paths['PRETRAINED_MODEL_PATH']}
!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME}

"""# backup folder for object detection image set
<br> ![danger.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAANwAAADBCAYAAACkEt7EAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAABmJLR0QA/wD/AP+gvaeTAAAAB3RJTUUH4QgJFRYxCx+yugAAGlFJREFUeNrtnXmQVPW1xz+3u6fXmYFpmQUYlHUWNhkRFNGAYFxwAVEUFHeCCVGjKEZUBAFRAZ3hj/dIrEpMWZW88lkpK/qk8hJefNFojOISRXHABcVhmO5hhl1opvu+P+68iMrS031P9+2e86mav6b73P4t33t+v3t/5xxQFEVRFEVRlLQwtAtygx0wwAVzgclAJWACXwLr3fDUSbBNe0lR0hdaKAJPRyAeAfMYfx1RWPs5+LXH1MMpKbIdTnHDOgOGJvmVdw24uBSatfdUcEoX2AYBP7xlwrAufnVDKYw3IKa96Dxc2gXOxAcPpSA2gNOjcK/2oHo4JUlaYKABH1m6S4mvO6C2D3yhvakeTjnxoDyZhtgAAm5YoT2pHk45Aa0wKQH/Y4MpE5hQBq9qr6qHU46uEHcCGmy8mTaYOsYqOOXoROHHwAgbTZ4Wheu1Z3VJqXyHXVASg81AL5tNt7ih6iTYo72sHk7pJAYPC4gNoDwOC7WH1cMpnbRCbQL+CRQI7Q1jBgwvgy3a2+rhuj0J6zVAgZR9A7zA49rT6uG6PVG41IQXMnEtEy4ohz9pr6vguiUmeKPwAVCVoet9VAanGtChva9Lym5HBO7IlNg6765DI/Aj7Xn1cN2OHVDmsl4D9MiwV207DFWVsFNHQT1cd+r4RzItts47bNgLi3QE1MN1p6XkKGAD4M7ST+hIQF0FbNTRUA/XHWjIotgAPG6o12FQwXUH73YVMCHbv8OE86JwsY6ILinzls/BH4JNQH+H/KRPdsPwIXBIR0c9XN5RCAscJDaAwT3hpzoy6uHyjlbom4BGIOSwn7YHqC6DHTpK6uHyBhMec6DYAIpNWKIjpB4ub9gBZ7rgdQf3d8KAsaXwto6Werhc92yGAWscfnNzmVY6Br0Bq+Bymyhcb8DYHPipZ0fhCh0xXVLmLBEoxHpQ0idHfvK2DqjpAwd09NTD5SILc0hsAP08cJcOm3q4nKOzvNRH5F5FmwNuqNHyV+rhcq1jV4mJzesFt9hRzGAclusIqofLGaIw0YSXxRRxzz2Y+/fz9dq1UpcwEzCuAv6ho6mCczQmuKPW+6xTRTxnWRnhzZshHqetqorETrE40jdK4SzDSpmu6JLSmXSmMDhVyn5o+XKMHj0wwmGCDz4o2ZQzI3Ctjqh6OMeyE4rjVtqEcgn7nlGjKNmw4Zv9W0cH7XV1dGwUiyNtAmrKYJ+Orno4x9FhnUksl7Jf2NDw7YclHg+hetE40r7Az3Vk1cM5cSk52IQPO5Ou2o7vqqsofvbZo/5v9yWXEHvpJammHYxDbW/YqqOsgnOS4F4CpogMkt9PyaZNuPv3P+r/4598Qvvw4ZiHxOJInyuzItUVXVJmnxY4T0psAIEFC44pNgD34MH4fyoaRzoj6oC0EOrhFEzwtMJ7JgwTuSP27Uu4sREjdPxQOnPPHtqqq0nsEIsjfa8UTjcgrqOuHi5rtMLtUmIDCD322AnFBmAUFxNaskSyqaNa4WYdcfVwWWM3hA/CFgPCEvYLzjyTnq+/bkXUJUMiQfvYsXS8LRZHGimA6hLYpaOvHi7jxOARKbFhGIQaGpIXG4DLZb06MMTuo2UxeFBHXgWXcZphmAlzpOz7r7+egjPO6LpXPPtsfNOnSzb99ihU6wzQJWVGiVh11n4oMiiFhYQbG3H1SS2ULvHll7TV1mIeEIsj/a8yuFRngXq4jNAC06XEBhBcuDBlsQG4Tj6ZwF2icaSXROBCnQnq4cTpLKK4ERgiYd89YAAlH32E4U8vlM48cIC2mhoS28TiSDeVWsUdD+usUA8nRhTulhIbQGjVqrTFBmAEg4SWi8aR1kbhJzoj1MNJLiXLDSsaoFjCfsHEifR82ca4VdNk17hxHP6HWBxpewdU9YFWnR3q4STuTo9LiQ2Xi8LVq23+wSm8WugaJR54WGeGCk5iKXkacJ2Uff+PfoRn9Gj7veaZZ+K/VjSO9NYWGKkzRJeU9q3MwIjCK8DZIoNQXGy9BqioEPn9iaYm2mpqMPftk+qfv5TDZJ0p6uFsoRWukRIbQGjJEjGxgXUAOvhzuThSAya1wDSdKerh0mYbBLzwsQEnS9h3Dx5M+MMPrdR3kl764EHaa2uJb90qdYnPdsNQLe6oHi4tvLBQSmwAhWvWiIsNrCDW0MqVkpcY2APu1BmjHi5ldkK/OHwMBEXEfN559PjznzPapl0TJ3L4r3+VMr/XgOpSaNbZox6uy8RhtZTY8HisR/YZ5nuJiOylyIRHdOao4LpMC5wFzJCyH7jtNjzDhmW8XZ5Ro/DfLBpHekNrbpTn0iWlUzDBFbXSfJ8u0unhMOHNm3GddFJW2peIRGirrsbctUvqEn8vhfGatVk9XFJ0phI4Xcp+6JFHUhZbLBbjq6++oqmpiVgsltqgl5URks3aPK4VZupMUg93QqLWPqQR6C2ypBs2jJL33gOPJ+nvvPPOOzzzzDOsW7eOLVu2fOt/tbW1TJkyhRtuuIERI0Z0Rbm0jRxJvLFRqiu/SkBNBezXWaUcT3CrImBK/R3605/MZPnqq6/M6dOnm4ZhmNZK99h/LpfLnDlzptnS0pK0/UMvvmhKtrXFykStqIc75oOSQQZ8CPgk7PumT6f4979P6rOvv/46V1xxBTu6mPauX79+PP/884xO8lzm7osuIvbHP0p16dcdUNsHvtDZpYL7HhF4AanUAV4v4Y0bcQ85cShdY2MjZ5xxBrt3707pUuFwmDfffJNBgwad8LPxTZtoO/VUOCwTR2rCf5RbR+MUfWjyDTusw7dieTqCd9+dlNhisRhTp05NWWwAbW1tzJgxg3j8xDlb3bW1BH4iF0dqwKwInKMzTAV35F3Y7QKxMjSu8nKC992X1Gd/85vf0GjDg4x3332X5557LqnPhpYswdWrl2QXrzF1rqngjnhQMg8YIWU/9PjjGMXJxa2utjEIddWqVcl5oZISgg+LxpHWReFGnWm6h2MXlMRgCyDyFtpz2mmUvPUWuE58b/v0008ZPHiwfYNrGDQ3N1NenkTJunic9tNOo+P998W2yB6oCsPu7jzfur2Hi8EyKbFhGFY0gCu5bn7llVfsXSqbZvI23W4KZYs7lnXAQl1SdmN2wlBgrpR93zXXUHB28nGrWwVi1b74Ivkn8gWTJuGbNk1yr3xXRDDjmQrO4cThSaBAxLkFAhSuWNG1G8DOnfbfVLpoM/TEExg+kdeQGOA1YKUKrhuyA6YCF0jZDy5ciOvkrsWt7t9v/ymovXv3dunz7oEDCdx5p6SXm9YC56vguhEmeF2Cd1pXv34E7r6760tQAc/iTyGpbPCBB3D17i05BPUmeFRw3YSIlQqgSsp+4erVGMFgzgrOKCoSzdpswNCI4N5ZBeespWSZAfdL2S846yx8M2ZkTBxSIvbfeCOeMWMkh2LZV1JPh1VwjmrwCqCHjHGX9RogxUzHEoJL2WaabUnCy4W98JAKLr+XknXATVL2/TffjOf00zMvDiGbBePG4ZspGkc6bwcMV8HlLw1SbTaKiggtXZqWjeJi+8sW9OiRnjMvXLkSIxSSGg+P2xoTFVy+EbVC/n8gZT+4aFHaT/Z69uxp++9K16arspLgggVi42LC5ChcooLLI7ZBAHhMyr570CACd9yRdXFIeDiAwL334j7lFEnRNWwRCvpVwWUBP9xrgtiMKayvt+V0hh3ikBCxEQgQevRRySEa1BNuU8HlAa3Q1wSxNZF38mS8l17qGHFIidg3axYF58jFkZqwOAIVKrgcJ26dKJHZ9bvdhGw8Ye9UD/cvT96FyIcUKDJhqQouh2mBcQbMkrIfmDcPz4gRjhQHWPFwRUVFttnz1NXhv+EGsfEy4JaoYD5QJ5C3AagmuCLwd0Mo7bZRUkJ4yxZbsyebponX66Wjo8MWe8XFxWnlRjkaiZYWK2vzbrE40tdK4Zx8zdqctx4uCjcYgjnuQ0uX2p6q3DAMSkpKbLN3kkAqdVd5OcGFonGk46NwpS4pc4gIFCJYxcVdW0vg1ltFbNspkpOEahcE77orqQxkafDEdqmqRSo4ER5AKFU5WK8BKBCJWyUcDjvS1rfweqWLO/bzwHwVXA7QAgMRrMTpmzoV7wVicas54eEAfNOm4T1fNI50YZtg5VkVnF37IKuIol/EuPydPTc83JGe3iMWRxqM52Fxx7wSXBTOBS4XmwF33om7qipnBHeScP0599ChBObKxZGacG0EzlbBORAT3KbgyXNXWRnB++8Xb0cueTiA0LJlkoUlDaAhn7I2501DOkP2R4pNrBUrMHr0EG+HnV4pE4IzwmGCD4nGkY6OwGwVnIPYBSWG4LEgT10d/ptuykhbcmlJ+f8E5s3DM1wujtSAlTuhWAXnEGKwGBCrRlHY0CB5hjCnPZx1R/IQamiQvEJ5HO5VwTmAVqjBKsYhgu/qqyn4wQ8y1p5c9HDQGTVxiWgc6T0RGKyCyzIJ4ezJoccey2h7ctLDHbESkMrajBWg+pgKLotE4WLgIrG9yb334u7fP6NtskskLpdLJL7ueLgHDcJ/m2gc6RUt8MNcnrM5Gy1gQkEUPgCqRe5EffsSbmyUTKBz7Fu5z0csFktbuBK1Ck44Lnv30lZVRaKLtcm7MGE/7AWjDOjIxXmbsx6uFW6XEhuIZ6sS93KZXk7+SxA2ZC87wY12WCvcokvKDNIMpSYskrJfMG4cvlmzstY+O8SSyQcm38V/yy1p5edMQnTL2qGnCi5zP3o5Uh3uclmvAYzsrbbtEEu2PFyG+rA0JnjDVcEdQQucagguKfzXX49n7NistjHXPRxAwfjx+K6UiyM14Pao4JZCBfdNRzcAbhHbhYWEHsn+AfVc3sN9ax/8xBMpVRFKVtMmPKGCEyRihd5PlLIffOABXH36ZL2dOb+k/P/J1a8fgfmicaQXRwRfC3VrwXVm5hXLRipd+bO7LSn/dRNLoRJsF3nSFDr40K0F1wPuQfBoT2j1agy/P28E5wQPB2AEg6LFHYGaVvipCs7epWQFgodXC849F9/llzumvXZ4J6d4OAD/7NkUnC0XR2rC4u2Ch9e7neAMK3uyTHiG2209wnYQ+eThrAE0pCMuehbkSNZmxwsuCqNNuFbKfmDuXDwjRzqqzfny0ORIPKNH458tF0dqwtwWwQBkG52HczHBiMKrwHiRxpeUEN68GVcvZ61Gtm3bxslpPmhob2/P+OHlE5FoaaGtqgpzzx6pS7xcBpPUw6W+d5stJTaA0OLFjhObHR7O7XaLVFNNe7KVlxO8VzSO9NwWwSRSee3htkPQDZsModyE7poawu+/L5bQNe2lbiDAwYMHU/pur169iEajzly1HDpE+/DhxD/5ROoSn+2HYQPgoBPb71gP54H7DcFEoIVPPulYsaW7B3PSE8rv3eF9PunijgNDgomA81JwO6EfcJeUfe/FF+O9yNkHFNIRjdMemHwX35VX4j3vPMlLPBCFPiq4JIlbaRNkDuEVFFD4hPOP4PVKY2/Zq5fzX0mFVq8Gt1vKfKHp0KzNjhNci/WQ5AqxvdHtt+Oudv4h81PSKGLfP8NpIVLaMpx6Kv45cyQvcUOrYLmyvBCcCS4D1iD0MMdVWkpoUW6EUQ0YMCAr382ol1u2DEPu1YWRsLI2Gyq4Y9AKc4DRYgO8fLnkANvKkDTqrw2Rrd2WSzfAca2CJadTugs45YdEraLqm7HOTYosYUreflty32ArH3/8MbW1tSl9t6mpiT59+uREOzl8mLYRI4g3NkpdoSkB1RWwXz3cESSs7MkVUvYLGxpyRmwAVVVVFBUVdfl75eXluSM2yMRDrL6Gg7I2O0JwERhsgFhCQ9+VV1IwcSK5hMvlYsKECV3+3qRJk8g1pF/TGLCgGfqr4L6hASvA1P7Oln/RKsaFF16Yke84AeGDCAG3Q7I2Z11wLXAeVgZlmZ6+5x7cg3MzJf3VV1+NvwtBsYWFhUybNi0n2+quqSEwb55od0bgB91acCZ4DKgXa1xFhfRhWVF69erF7C6EtMyZM8eRh5aTJQOHybNe3DGrF49aofFihcVCK1diFOd2WbGVK1cm9RK8urqa5bKpDMQxSkoILhWNI62Lwk3dUnC7IYxgMk/P6NH4r72WXKekpIQ33niDKVOm4DpKxLTL5eLyyy/nb3/7G6EspWa3dQsgHxC8og16ZO2mkq0LR+DfkKrrZhj0fPVVCsaPJ5/YunUrGzZsoKmpCcMwqKysZOzYsVRWVuZVOw+//DK7BJ+2GrCqNEuvCrIiuJ0wNA7/BDwS9v3XXUfRM8+g5C57pk/n0PPPSz07iLlgRKl10CL/BReB/wbOF2lQMEh40ybpXIiKMPHPPqN92DDMgwelRPdCOUzN+z1cZwj8+VL2M5B4VMkA0ol5DbisBS7Iaw9ngjcKGwGR07Wufv0If/yxZD57JZPzZd8+2qqrSWzfLnWJTaVWcZjDeenhojBfSmwgXjxCybQ3kC+uUhuFW/PSw7VAuWFtUkVejBWMH0/PV1/Nal03RYBEgvZx4+h4802pK7THYEglZKQ+syuDyn5USmy4XBSuWaNiy0fkizuWeK1IlfzxcBGoAzZICdw/dy5Fv/xlXs+7AwcOsH79ejZu3MiOHTswDIPevXszcuRIJk2a1KUzl7nInmuv5dDvfidlPp6Augr4IOcF15k9+a/AOSINKCqysidXVOTlRNu2bRuLFy/m2Wef5cCBA0ffuxYWMnv2bB566CF69+6dnyvLpibaqqsx9++Xmqd/KYfJOb+kbIWZUmKDzgOveSq2tWvXUlVVxdNPP31MsQHs27ePX/ziFwwZMoRn8vSFv6tvX4ILFkh6nklRuCynPdw2CPhhkwmnSNh3DxpEyYcfYvh8eTfB5s+fT319aoEUixYtYunSpXnXJ+bXX9M+dCjxrVulLvHpbhg2BA7lpIfzws+lxAZW2oR8FFt9fX3KYgNYtmwZTz31VN71ixEIEHpMNI50UDHckZMebidUxuFjQOQIu3fyZHqsX593k2rjxo2MGjWKeDyelh2fz8dHH33EwIED866Pdk2YwOFXXpEyv9eA6lJozikPF4dVUmLD4yHksCKKdrFw4cK0xQZw6NAhFuVIDs5UVjaCxR2LTMHijiIergXGGfCalP3Az37muKqldvDFF18wYMAATNO0Z4/rdtPc3ExpaWne9dXeOXM4+KtfSZlPGHBGqfUqy9keTjp7shEOE8zTO/cf/vAH28QGEI/Heemll/Kyr0IrVmD0EIsjdZmwRiJrs+2Ci8KNwBixjl62DJeDyzGlw9tvv50TNp2Aq6yM4P33S17irCjMcLTgolAEiCXWcA8dSmDuXPKV7QKn4puamvK2v4J33om7qkryEqu321zFyW4P9yAgdtShsL4ePJ68nUCxWMx2mwcPHszb/sLrJbRypeQV+hXAPY4UXAsMNOFnUi33TZuG9/zzyWcqBE7M9O3bN6/7zDd1Kt4L5OJITbivzcZKvC4bDT2JUPbkDNzJHEGVwPIoVyrppL3yEczafBhWOEpwrTDJFMwPEZw/H3c3mDiXXHKJ7TYvvfTSvO83d20tgVvl4kgNuCYCZ9tkK22X647Cu8AIica6yssJb96c8wldkyGRSFBTU8OWLVtssVdXV8c777xDd8Bsb6dtyBASO8XiSN8phTEGJLLq4aLwYymxAYQefbRbiA2spK52Zk9+NEeLmKTkOUpKCC4WjSM9LQrXZdXD7YKSmJU2QSQhvKeujpINGySP8TjvTm2aTJ06lRdffDEtO7NmzeJ3cgGbziQep72ujo4PxOJIW9xQdRLsyYqHi8HDUmLDMKy0Cd1IbFazDX77298yYkTqi4YxY8bwK7ljTw7ezLkJ1ddLXqE8DvdlZUnZCrVYy0kRfDNnUnDOOXRHioqKeO2111J6iDJlyhTWr19PIBDoln3nnTwZr+CDIhPujqSReS5lwSWs1wAiz2KNQCBniyjaKbrnn3+etWvXJvV+rrKykl//+te8+OKLOV2yyg4K6+vF4iQN8JJGcceU9nBRuNSEF8QelCxZIr0BzikOHDjAunXreOGFF9i4cSPNzc0YhkGfPn0YOXIkl112GRdeeGHeJxLqCvsXLODA6tWSnu78cvizuOA6syd/AIgcYnNVVlrZk/Og9JKSPcy9e62szc0icaQY8GEvGGVAh+iSMmKFoIudGC1ctUrFpqQviKIiQoJ5XUwYFoE5oh5uB5S5rNcAIoFIBePG0fO11zShq2IPiQTtZ5xBx4YNUqJrOwxVXcna3CUP54JHpMSm2ZOVXJtTBoS9VoSM/UvKCIxCsD6y/8Yb8YwZo5NEsXfVdNZZ+GbMkLzEbc0wzPYlZQT+F5ggtd4ONzbiytOswUqWV5bbttFWU4N5nGS6aXq69aXwQ9s8XASukhIbQPDBB1VsitzKsl8/AnffLWbfhPMiMCWZz54wfPpz8AOPS66zE83N7L/vPp0ZipwohGoSHMEaE9YbEEtrSRmFRZJ5+hQlXzBgfinUpyy4VuibgEakEroqSn6xB6gugx0p7eHi1lJSxaYoyVFswpKUPNwOONMFr5PBssSKkgckDBhbCm8n7eFM61XhGhWbonQZlwmru7SkjML1BozVvlOUlJjYAlcktaSMQCHWg5I+2m+KkjKf74ehA+DgcT2cAfNVbIqSNgMKYd5xPZwJBVHYjlSeEkXpRpjwZRn0N8A8qoeLWFVvVGyKYgMGnNwCw4+3pByk3aQotopu0PEEV6FdpCi20vt4gmvW/lEUW/dx248nuE+1ixTFVj79zhLzW2r0RKEJKNN+UpS02VoKA4/5lLIz5dca7SdFsYX6I8X2PQ8HsAV8PWAD33mcqShKl3irFM76bt7K7500GQKHEnAZ8Ln2maKkRKMB046WJPaoh5cr4HMvjJZMZ64oecp/GjCm9DtPJ4+5pPwuLTDOBfNMuBA9haIox5AJ6wz491JrO3ZMuhTvFoFCr1DFHEXJRWJwuAz2aU8oiqIo3Zv/A+HL5T+IC1AvAAAAJXRFWHRkYXRlOmNyZWF0ZQAyMDE3LTA4LTA5VDIxOjIyOjQ5KzAwOjAwuslNKQAAACV0RVh0ZGF0ZTptb2RpZnkAMjAxNy0wOC0wOVQyMToyMjo0OSswMDowMMuU9ZUAAAAASUVORK5CYII=)
<br> <u>**Backups are so important to have!!!**</u>
"""

import shutil

source_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train2_converted'
backup_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train3_converted'

# Create a backup of the source folder
shutil.copytree(source_folder, backup_folder)

"""# CREATE LABEL MAP"""

import xml.etree.ElementTree as ET
from collections import Counter

"""The following functions are made to check the .xml files are all present for each image."""

def extract_labels(xml_file_path):
  labels = []

  tree = ET.parse(xml_file_path)
  root = tree.getroot()

  for obj in root.findall('object'):
    name = obj.find('name')
    if name is not None:
      labels.append(name.text)

  return labels

def get_unique_labels(folder_path):
  all_labels = []

  for xml_filename in os.listdir(folder_path):
    if xml_filename.endswith('.xml'):
      xml_path = os.path.join(folder_path, xml_filename)
      labels = extract_labels(xml_path)
      all_labels.extend(labels)

  unique_labels = list(set(all_labels))
  return unique_labels

folder_path = '/content/drive/MyDrive/OBJ_DETECTION_IMGS/TREES_OBJDET/test'
unique_labels = get_unique_labels(folder_path)

print("Unique labels found in the XML files:")
for label in unique_labels:
  print(label)

xml_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtrain"
labels = set()

# Loop through XML files in the directory
for xml_file in os.listdir(xml_dir):
  if xml_file.endswith('.xml'):
    xml_path = os.path.join(xml_dir, xml_file)
    tree = ET.parse(xml_path)
    root = tree.getroot()

    for obj in root.findall('object'):
      label = obj.find('name').text
      labels.add(label)

label_list = list(labels)
print("Labels found in XML files:")
print(label_list)

#labels = [{'name':'birds', 'id':1}, {'name':'car', 'id':2}, {'name':'cliff', 'id':3}, {'name':'cloud', 'id':4}, {'name':'hay-bale', 'id':5}, {'name':'House', 'id':6}, {'name':'Lake', 'id':7}, {'name':'human', 'id':8}, {'name':'tree', 'id':9}]

with open(files['LABELMAP'], 'w') as f:
  for label in labels:
    f.write('item { \n')
    f.write('\tname:\'{}\'\n'.format(label['name']))
    f.write('\tid:{}\n'.format(label['id']))
    f.write('}\n')

labels = [{'name':'car', 'id':1}, {'name':'house', 'id':2}, {'name':'person', 'id':3}, {'name':'rock', 'id':4}, {'name':'sheep', 'id':5}, {'name':'vegetation', 'id':6}, {'name':'water', 'id':7}]
#with open(files['LABELMAP'], 'w') as f:
#  for label in labels:
#     f.write('item { \n')
#     f.write('\tname:\'{}\'\n'.format(label['name']))
#     f.write('\tid:{}\n'.format(label['id']))
#     f.write('}\n')

image_folder = ['/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtest']

for folder in image_folder:
  for root, dirs, files in os.walk(folder):
    for file in files:
      if file.lower().endswith(('.jpg', '.png', '.jfif', '.jpeg')):
        image_path = os.path.join(root, file)
        try:
          img = Image.open(image_path)
        except Exception as e:
          print(f"Error processing image: {image_path}")
          print(f"Error message: {str(e)}")

for folder in image_folder:
  for root, dirs, files in os.walk(folder):
    for file in files:
      if not file.lower().endswith('.xml'):
        image_path = os.path.join(root, file)
        try:
          # Use TensorFlow to load the image
          img_raw = tf.io.read_file(image_path)
          img = tf.image.decode_image(img_raw)

        except Exception as e:
          print(f"Error processing image: {image_path}")
          print(f"Error message: {str(e)}")

"""Some images cannot be processed by the Tensorflow image processing module. This seems to be a common problem when using images collected from Google. They are all .jpg files so the error doesn't really help:
```
<br>Error processing image: /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake3.jpg
Error message: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name:

```
It could be worth analysing the images to see if some outlying pixel values are causing the issue.

# Processing the pixel values to help image processing
"""

import tensorflow as tf
import cv2
import os

def preprocess_image(image_path):
    # Read the image file
    image = tf.io.read_file(image_path)

    # Decode the image
    image = tf.image.decode_image(image)

    # Normalize pixel values to [0, 1]
    image = tf.cast(image, tf.float32) / 255.0

    return image

image_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train_small'

for root, dirs, files in os.walk(image_folder):
    for file in files:
        if file.lower().endswith(('.jpg', '.png', '.jfif', '.jpeg')):
            image_path = os.path.join(root, file)
            try:
                img = preprocess_image(image_path)
            except Exception as e:
                print(f"Error processing image: {image_path}")
                print(f"Error message: {str(e)}")

for root, dirs, files in os.walk(image_folder):
    for file in files:
        if file.lower().endswith(('.jpg', '.png', '.jfif', '.jpeg')):
            image_path = os.path.join(root, file)
            try:
                img = cv2.imread(image_path)
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB
                img = img.astype(float) / 255.0  # Normalize pixel values
            except Exception as e:
                print(f"Error processing image: {image_path}")
                print(f"Error message: {str(e)}")

"""Nope still the same images. There is a module called 'imghdr', which is able to do the following:
*   Find out if the file is not actually an image extension
*   Find out if the extension actually indicates the true extension (the extension is often not a true indication)
*   Evaluate if the TF module can read the images.
Let's run this helpful function:




"""

from pathlib import Path
import imghdr

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/train_small"
image_extensions = [".jpg", ".png"]  # Add all your image file extensions

img_type_accepted_by_tf = ["bmp", "gif", "jpeg", "png"]

for filepath in Path(data_dir).rglob("*"):
    if filepath.suffix.lower() in image_extensions:
        img_type = imghdr.what(filepath)
        if img_type is None:
            print(f"{filepath} is not an image")
        elif img_type not in img_type_accepted_by_tf:
            print(f"{filepath} is a {img_type}, not accepted by TensorFlow")

"""OK, this looks like the issue. The extensions are seemingly JPEG, but in reality, these are WEBP images renamed to .jpg image files.

Got to remember to carry over the .xml files as well! This caused me problems thinking my GPU was crashing.
"""

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/train_small"
output_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/train_small_converted"
image_extensions = [".jpg", ".png", ".webp"]

if not os.path.exists(output_dir):
    os.makedirs(output_dir)

for filepath in Path(data_dir).rglob("*"):
    if filepath.suffix.lower() in image_extensions:
        img_type = imghdr.what(filepath)
        if img_type is not None and img_type == "webp":
            img = Image.open(filepath)
            output_image_path = os.path.join(output_dir, filepath.stem + ".jpg")
            img.save(output_image_path, "JPEG")
            print(f"Converted {filepath} to JPEG")

            # Move corresponding XML annotation file
            xml_filepath = filepath.with_suffix(".xml")
            if xml_filepath.exists():
                output_xml_path = os.path.join(output_dir, xml_filepath.name)
                xml_filepath.rename(output_xml_path)
                print(f"Moved {xml_filepath} to {output_xml_path}")

        else:
            output_image_path = os.path.join(output_dir, filepath.name)
            img = Image.open(filepath)
            img.save(output_image_path)
            print(f"Copying {filepath} as it is")

            # Move corresponding XML annotation file
            xml_filepath = filepath.with_suffix(".xml")
            if xml_filepath.exists():
                output_xml_path = os.path.join(output_dir, xml_filepath.name)
                xml_filepath.rename(output_xml_path)
                print(f"Moved {xml_filepath} to {output_xml_path}")

"""In converting some of the images to JPEG format, we see
```
Converted /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake3.jpg to JPEG
Moved /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake3.xml to /content/drive/MyDrive/Tensorflow/workspace/images/train_small_converted/Lake_lake3.xml
Copying /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake1.jpg as it is
Moved /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake1.xml to /content/drive/MyDrive/Tensorflow/workspace/images/train_small_converted/Lake_lake1.xml
Copying /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake92.jpg as it is
Moved /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake92.xml to /content/drive/MyDrive/Tensorflow/workspace/images/train_small_converted/Lake_lake92.xml
Converted /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake115.jpg to JPEG
Moved /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake115.xml to /content/drive/MyDrive/Tensorflow/workspace/images/train_small_converted/Lake_lake115.xml
Converted /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake67.jpg to JPEG
Moved /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake67.xml to /content/drive/MyDrive/Tensorflow/workspace/images/train_small_converted/Lake_lake67.xml
```
So, five images have been processed, now to go back and test their tensorflow accessability.
"""

image_folder = ['/content/drive/MyDrive/Tensorflow/workspace/images/train_small_converted']
for folder in image_folder:
    for root, dirs, files in os.walk(folder):
        for file in files:
            if not file.lower().endswith('.xml'):
                image_path = os.path.join(root, file)
                try:
                    # Use TensorFlow to load the image
                    img_raw = tf.io.read_file(image_path)
                    img = tf.image.decode_image(img_raw)

                except Exception as e:
                    print(f"Error processing image: {image_path}")
                    print(f"Error message: {str(e)}")

"""Brilliant, no issues here now. It could be simpler to delete these problem images, but why get rid of that data I worked so hard to annotate?

After, doing the same with the test folder...
"""

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/test_small"
image_extensions = [".jpg", ".png"]  # Add all your image file extensions

img_type_accepted_by_tf = ["bmp", "gif", "jpeg", "png"]

for filepath in Path(data_dir).rglob("*"):
    if filepath.suffix.lower() in image_extensions:
        img_type = imghdr.what(filepath)
        if img_type is None:
            print(f"{filepath} is not an image")
        elif img_type not in img_type_accepted_by_tf:
            print(f"{filepath} is a {img_type}, not accepted by TensorFlow")

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/test_small"
output_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/test_small_converted"
image_extensions = [".jpg", ".png", ".webp"]

if not os.path.exists(output_dir):
    os.makedirs(output_dir)

for filepath in Path(data_dir).rglob("*"):
    if filepath.suffix.lower() in image_extensions:
        img_type = imghdr.what(filepath)
        if img_type is not None and img_type == "webp":
            img = Image.open(filepath)
            output_image_path = os.path.join(output_dir, filepath.stem + ".jpg")
            img.save(output_image_path, "JPEG")
            print(f"Converted {filepath} to JPEG")

            # Move corresponding XML annotation file
            xml_filepath = filepath.with_suffix(".xml")
            if xml_filepath.exists():
                output_xml_path = os.path.join(output_dir, xml_filepath.name)
                xml_filepath.rename(output_xml_path)
                print(f"Moved {xml_filepath} to {output_xml_path}")

        else:
            output_image_path = os.path.join(output_dir, filepath.name)
            img = Image.open(filepath)
            img.save(output_image_path)
            print(f"Copying {filepath} as it is")

            # Move corresponding XML annotation file
            xml_filepath = filepath.with_suffix(".xml")
            if xml_filepath.exists():
                output_xml_path = os.path.join(output_dir, xml_filepath.name)
                xml_filepath.rename(output_xml_path)
                print(f"Moved {xml_filepath} to {output_xml_path}")

image_folder = ['/content/drive/MyDrive/Tensorflow/workspace/images/test_small_converted']
for folder in image_folder:
    for root, dirs, files in os.walk(folder):
        for file in files:
            if not file.lower().endswith('.xml'):
                image_path = os.path.join(root, file)
                try:
                    # Use TensorFlow to load the image
                    img_raw = tf.io.read_file(image_path)
                    img = tf.image.decode_image(img_raw)

                except Exception as e:
                    print(f"Error processing image: {image_path}")
                    print(f"Error message: {str(e)}")

"""# Create TFRecords
This is in order to store annotation data in specific format for model training.
"""

ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')
if os.path.exists(ARCHIVE_FILES):
  !tar -zxvf {ARCHIVE_FILES}

if not os.path.exists(files['TF_RECORD_SCRIPT']):
    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}

"""Had to open the generate_tfrecord.py file and edit some code, specifically the function that parses and extracts the information from the .xml files. The problem I was encountering comes from the length of the < object > class if you download from Roboflow is slightly longer than the .xml files created manually with labelImg. The function below is able to handle these differences by measuring the length of the < object > class. For some frustrating reason, there isn't a universally respected order of the < ymin >, < ymax >, < xmin >, < xmax > objects, so some datasets have these in a different order. This function will accommodate these discrepancies.

    xml_list = []
    for xml_file in glob.glob(path + '/*.xml'):
        tree = ET.parse(xml_file)
        root = tree.getroot()
        for member in root.findall('object'):
            class_name = member[0].text
            
            if len(member) == 5: # Handling Roboflow XML format
                bbox = member.find('bndbox')
                xmin = int(bbox.find('xmin').text)
                ymin = int(bbox.find('ymin').text)
                xmax = int(bbox.find('xmax').text)
                ymax = int(bbox.find('ymax').text)
            elif len(member) == 6:  # Handling labelImg XML format
                bbox = member.find('bndbox')
                xmin = int(bbox.find('xmin').text)
                ymin = int(bbox.find('ymin').text)
                xmax = int(bbox.find('xmax').text)
                ymax = int(bbox.find('ymax').text)

            value = (root.find('filename').text,
                     int(root.find('size')[0].text),
                     int(root.find('size')[1].text),
                     class_name,
                     xmin,
                     ymin,
                     xmax,
                     ymax
                     )
            xml_list.append(value)
"""

from PIL import Image
import os
import imghdr
from pathlib import Path

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/train2"
image_extensions = [".jpg", ".png", ".webp", ".jpeg"]

for image_path in Path(data_dir).rglob("*"):
  if image_path.suffix.lower() in image_extensions:
    img_type = imghdr.what(image_path)
    if img_type is not None and img_type == "webp":
      img = Image.open(image_path)
      img = img.convert("RGB")  # Convert to RGB mode
      img.save(image_path.with_suffix(".jpg"), "JPEG")
      print(f"Converted {image_path} to JPEG")

      # Find corresponding XML annotation file
      xml_filename = image_path.stem + ".xml"
      xml_path = os.path.join(data_dir, xml_filename)
      if os.path.exists(xml_path):
        shutil.copy(xml_path, image_path.with_suffix(".jpg").with_name(xml_filename))
        print(f"Copied {xml_path} to {image_path.with_suffix('.jpg').with_name(xml_filename)}")
    else:
      img = Image.open(image_path)
      img = img.convert("RGB")  # Convert to RGB mode
      img.save(image_path)
      print(f"Converting {image_path} to JPEG")

      # Find corresponding XML annotation file
      xml_filename = image_path.stem + ".xml"
      xml_path = os.path.join(data_dir, xml_filename)
      if os.path.exists(xml_path):
        shutil.copy(xml_path, image_path.with_name(xml_filename))
        print(f"Copied {xml_path} to {image_path.with_name(xml_filename)}")

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/NEWERtrain2_converted'
label_map = {label['name']: label['id'] for label in labels}
class_counts = {label['name']: 0 for label in labels}
for file in os.listdir(train_folder):
  if file.lower().endswith((".jpg", ".jpeg", ".png")):
    for label in labels:
      class_name = label['name']
      if file.startswith(f"{class_name}"):
        class_counts[class_name] += 1

for label in labels:
  class_name = label['name']
  count = class_counts[class_name]
  print(f"Class: {class_name}, Count: {count}")

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/test2_converted'
label_map = {label['name']: label['id'] for label in labels}
class_counts = {label['name']: 0 for label in labels}
for file in os.listdir(train_folder):
  if file.lower().endswith((".jpg", ".jpeg", ".png")):
    for label in labels:
      class_name = label['name']
      if file.startswith(f"{class_name}"):
        class_counts[class_name] += 1

for label in labels:
  class_name = label['name']
  count = class_counts[class_name]
  print(f"Class: {class_name}, Count: {count}")

paths['IMAGE_PATH']

import os

image_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtest"
extensions = set()

for filename in os.listdir(image_dir):
  file_extension = os.path.splitext(filename)[1].lower()
  extensions.add(file_extension)

print("Unique file extensions in the directory:")
print(extensions)

xml_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtest"

for xml_file in os.listdir(xml_dir):
  if xml_file.endswith('.xml'):
    xml_path = os.path.join(xml_dir, xml_file)
    tree = ET.parse(xml_path)
    root = tree.getroot()

    for filename_elem in root.iter('filename'):
      new_filename = filename_elem.text.replace('.JPG', '.jpg')
      filename_elem.text = new_filename

    for path_elem in root.iter('path'):
      new_path = path_elem.text.replace('.JPG', '.jpg')
      path_elem.text = new_path

    # Save the updated XML
    tree.write(xml_path)

xml_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtrain"
xml_files_with_tree = []

for xml_file in os.listdir(xml_dir):
  if xml_file.endswith('.xml'):
    xml_path = os.path.join(xml_dir, xml_file)
    tree = ET.parse(xml_path)
    root = tree.getroot()

    for obj in root.findall('object'):
      name_elem = obj.find('name')
        if name_elem is not None and name_elem.text == 'tree':
          xml_files_with_tree.append(xml_file)
          break  # Once 'tree' is found, no need to check further

print("XML files with 'tree' object class:")
print(xml_files_with_tree)

xml_file_path = "/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtrain/housetp_8.xml"
new_object_name = "vegetation"

tree = ET.parse(xml_file_path)
root = tree.getroot()

for obj in root.findall('object'):
  name_elem = obj.find('name')
  if name_elem is not None and name_elem.text == 'tree':
    name_elem.text = new_object_name
    break  # Once 'tree' is found and replaced, no need to continue

# Save the updated XML
tree.write(xml_file_path)

"""The above functions are simply to check if the right image extensions exist. They also contain functions to make sure the .xml files all contain the right class names."""

!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'TOPDOWNtrain')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}
#!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'valid')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'valid.record')}
!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'TOPDOWNtest')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}

!cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}

"""# Configure pipeline

Configure pipeline of the model for my image files, label mapping, and most importantly transfer learning
"""

import tensorflow as tf
from object_detection.utils import config_util
from object_detection.protos import pipeline_pb2
from google.protobuf import text_format

config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])

config

pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()
with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], "r") as f:
    proto_str = f.read()
    text_format.Merge(proto_str, pipeline_config)

/content/drive/MyDrive/Tensorflow/workspace/annotations/test.record

pipeline_config.model.ssd.num_classes = len(labels)
pipeline_config.train_config.batch_size = 8
pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')
pipeline_config.train_config.fine_tune_checkpoint_type = "detection"
pipeline_config.train_input_reader.label_map_path= files['LABELMAP']
pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]
pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']
pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]

config_text = text_format.MessageToString(pipeline_config)
with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], "wb") as f:
    f.write(config_text)

print("Updated Pipeline Configuration:")
print(config_text)

"""# .XML FILES DEBUGGING

It can be investigated online on sites such as Stack Overflow, that .xml files on Roboflow sometimes contain dubious data, such as bounding boxes being larger than the images that contain them.

It looks like an unknown error is persisting when attempting to train the model. This could be caused by the massive amount of training images present for some classes.
"""

def count_images_and_annotations(folder_path):
    image_count = 0
    annotation_count = 0

    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.jfif', '.webp')):
                image_count += 1
            elif file.lower().endswith('.xml'):
                annotation_count += 1

    return image_count, annotation_count

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtrain'
image_count, annotation_count = count_images_and_annotations(train_folder)

print(f"Number of image files in 'train': {image_count}")
print(f"Number of annotation files in 'train': {annotation_count}")

image_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtest'
missing_annotations = []

image_files = [file for file in os.listdir(image_folder) if file.lower().endswith(('.jpg', '.png', '.jfif', '.jpeg'))]

for image_file in image_files:
    image_name = os.path.splitext(image_file)[0]
    xml_file = image_name + '.xml'
    xml_path = os.path.join(image_folder, xml_file)

    if not os.path.exists(xml_path):
        missing_annotations.append(image_file)

print("Image files without corresponding XML annotations:")
for missing_file in missing_annotations:
    print(missing_file)

print(f"Total number of missing annotations: {len(missing_annotations)}")

"""On a side note, it looks like two image files do not sport related annotation files in the training set."""

image_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train2'

images_to_delete = ['cloud63.jpg', 'cloud94.jpg']

for image_to_delete in images_to_delete:
    image_path = os.path.join(image_folder, image_to_delete)
    if os.path.exists(image_path):
        os.remove(image_path)
        print(f"Deleted image: {image_to_delete}")
    else:
        print(f"Image not found: {image_to_delete}")

def count_images_and_annotations(folder_path):
    image_count = 0
    annotation_count = 0

    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.jfif')):
                image_count += 1
            elif file.lower().endswith('.xml'):
                annotation_count += 1

    return image_count, annotation_count

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train2'
image_count, annotation_count = count_images_and_annotations(train_folder)

print(f"Number of image files in 'train': {image_count}")
print(f"Number of annotation files in 'train': {annotation_count}")

"""The below function checks for any outliers in the .xml annotation data."""

def check_xml_annotations(xml_folder):
    xml_files = [f for f in os.listdir(xml_folder) if f.endswith('.xml')]

    problematic_files = []

    for xml_file in xml_files:
        xml_path = os.path.join(xml_folder, xml_file)
        tree = ET.parse(xml_path)
        root = tree.getroot()

        width = int(root.find('size/width').text)
        height = int(root.find('size/height').text)

        for obj in root.findall('object'):
            bbox = obj.find('bndbox')
            xmin = int(bbox.find('xmin').text)
            ymin = int(bbox.find('ymin').text)
            xmax = int(bbox.find('xmax').text)
            ymax = int(bbox.find('ymax').text)

            if xmin < 0 or ymin < 0 or xmax > width or ymax > height:
                problematic_files.append(xml_file)
                break

    return problematic_files

xml_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtest'
problematic_files = check_xml_annotations(xml_folder)

if len(problematic_files) == 0:
    print("No problematic annotations found.")
else:
    print("Problematic annotations found in the following files:")
    for file in problematic_files:
        print(file)

"""There are loads of problematic .xml files which contain such issues as bounding boxes stretching from 'xmin=1' to 'xmin=641', when the image is only 640 wide, for the image below. It coould be seen this occurs in cases where the object carries on off the screen, and annotated as such, and later when the image is compressed, the pixel x-value is calculated to be off of the screen. As seen on Stack Overflow, it is necessary to delete these .xml files along with related images if you want to train the model correctly. ![8185a9c7-5b0a-4722-a336-0ee69d7d0ee4.jfif](data:image/jpeg;base64,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)

Now I will delete problematic pairs of image/xml files found in the training and testing sets.
"""

def delete_problematic_data(xml_folder, problematic_files):
    for xml_file in problematic_files:
        xml_path = os.path.join(xml_folder, xml_file)
        image_path = os.path.join('/content/drive/MyDrive/Tensorflow/workspace/images/train2', xml_file.replace('.xml', '.jpg'))  # Replace with the correct image folder and extension

        if os.path.exists(xml_path):
            os.remove(xml_path)
            print(f"Deleted XML file: {xml_file}")

        if os.path.exists(image_path):
            os.remove(image_path)
            print(f"Deleted image file: {xml_file.replace('.xml', '.jpg')}")

xml_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train2'
problematic_files = problematic_files

delete_problematic_data(xml_folder, problematic_files)



"""Now checking the amount of images in train:"""

def count_images_and_annotations(folder_path):
    image_count = 0
    annotation_count = 0

    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.jfif')):
                image_count += 1
            elif file.lower().endswith('.xml'):
                annotation_count += 1

    return image_count, annotation_count

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train'
image_count, annotation_count = count_images_and_annotations(train_folder)

print(f"Number of image files in 'train': {image_count}")
print(f"Number of annotation files in 'train': {annotation_count}")

"""There are about 1,000 less images in the training set, and then after performing the same with the testing set:"""

def count_images_and_annotations(folder_path):
    image_count = 0
    annotation_count = 0

    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.jfif')):
                image_count += 1
            elif file.lower().endswith('.xml'):
                annotation_count += 1

    return image_count, annotation_count

test_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/test'
image_count, annotation_count = count_images_and_annotations(test_folder)

print(f"Number of image files in 'test': {image_count}")
print(f"Number of annotation files in 'test': {annotation_count}")

import os
from collections import defaultdict

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train/'

# Initialize a dictionary to store the counts for each object class
class_counts = defaultdict(int)

# Loop through all XML files in the train folder
for xml_file in os.listdir(train_folder):
    if xml_file.endswith('.xml'):
        xml_path = os.path.join(train_folder, xml_file)
        with open(xml_path, 'r') as f:
            lines = f.readlines()
            for line in lines:
                if '<name>' in line:
                    class_name = line.strip().split('<name>')[1].split('</name>')[0]
                    class_counts[class_name] += 1

# Print the counts for each object class
for class_name, count in class_counts.items():
    print(f"Class: {class_name}, Count: {count}")

"""Although the number of images belonging to each class is uneven, particularly with 'human' and 'hay-bale', let's first see if the model is working after deleting these problematic files.

The problem still persists, and after looking online some more, it appears some .xml files can also contain negative values for width and height, or have bounding boxes with area 0. The following function will go over all .xml files again and check both the training and test set for this problem:
"""

def check_xml_annotations(xml_folder):
    xml_files = [f for f in os.listdir(xml_folder) if f.endswith('.xml')]

    problematic_files = []

    for xml_file in xml_files:
        xml_path = os.path.join(xml_folder, xml_file)
        tree = ET.parse(xml_path)
        root = tree.getroot()

        width = int(root.find('size/width').text)
        height = int(root.find('size/height').text)

        for obj in root.findall('object'):
            bbox = obj.find('bndbox')
            xmin = int(bbox.find('xmin').text)
            ymin = int(bbox.find('ymin').text)
            xmax = int(bbox.find('xmax').text)
            ymax = int(bbox.find('ymax').text)

            if xmin < 0 or ymin < 0 or xmax < 0 or ymax < 0 or xmin > xmax or ymin > ymax:
              problematic_files.append(xml_file)
              break

            box_width = xmax - xmin
            box_height = ymax - ymin
            if box_width <= 0 or box_height <= 0:
                problematic_files.append(xml_file)
                break

    return problematic_files

xml_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtest'
problematic_files = check_xml_annotations(xml_folder)

if len(problematic_files) == 0:
    print("No problematic annotations found.")
else:
    print("Problematic annotations found in the following files:")
    for file in problematic_files:
        print(file)

"""Let's see if this has had any effect on the command to train the Tensorflow model above.

On second thought, the pre-processing function built-in to the model may be encountering issues with certain resolutions in the training folder:
"""

def get_unique_image_resolutions(image_folder):
    unique_resolutions = set()

    for file in os.listdir(image_folder):
        if file.lower().endswith(('.jpg', '.png', '.jfif', '.jpeg')):
            image_path = os.path.join(image_folder, file)
            try:
                img = Image.open(image_path)
                width, height = img.size
                unique_resolutions.add((width, height))
            except Exception as e:
                print(f"Error processing image: {image_path}")
                print(f"Error message: {str(e)}")

    return unique_resolutions

image_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train'
resolutions = get_unique_image_resolutions(image_folder)

print("Unique image resolutions:")
for width, height in resolutions:
    print(f"{width} x {height}")

original_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train'

# Path to new folder to store selected images
new_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train_small'

original_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/test'

# Path to new folder to store selected images
new_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/test_small'
if not os.path.exists(new_folder):
    os.makedirs(new_folder)

labels = [{'name':'birds', 'id':1}, {'name':'car', 'id':2}, {'name':'cliff', 'id':3}, {'name':'cloud', 'id':4}, {'name':'hay-bale', 'id':5}, {'name':'House', 'id':6}, {'name':'Lake', 'id':7}, {'name':'human', 'id':8}, {'name':'pool', 'id':9}, {'name':'tree', 'id':10}]

num_images_per_class = 2

import random
import shutil
# Iterate through each class
for class_info in labels:
    class_name = class_info['name']

    # Get list of image files for this class
    class_image_files = [f for f in os.listdir(original_folder) if f.startswith(class_name) and f.endswith('.jpg')]

    # Shuffle the list of image files
    random.shuffle(class_image_files)

    # Select the first num_images_per_class
    selected_image_files = class_image_files[:num_images_per_class]

    # Copy selected image files and corresponding XML files to the new folder
    for image_file in selected_image_files:
        src_image_path = os.path.join(original_folder, image_file)
        dst_image_path = os.path.join(new_folder, image_file)
        shutil.copy(src_image_path, dst_image_path)

        # Get corresponding XML file
        xml_file = image_file.replace('.jpg', '.xml')
        src_xml_path = os.path.join(original_folder, xml_file)
        dst_xml_path = os.path.join(new_folder, xml_file)
        shutil.copy(src_xml_path, dst_xml_path)

print("Images and XML files copied to new folder.")

"""Nope, no negative values or boxes with zero area. The issue now must surely be the number of images, or, if not, there's an issue with one of the images collected via Roboflow. The only thing left to do now, is to collect all the images manually. This shouldn't be a pain as the video by Nicholas Renotte has explained that a much smaller number of images than I first thought is necessary for transfer learning. Hopefully, I can cover both possible issues at the same time by doing this relatively simple task. However, still an annoyance that I can't seem to rely on people online!

# MODEL TRAINING!
"""

TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')

command = "python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])

print(command)

!{command}

"""# Reflection of pre-processing and finally getting model to train

So, after completing several pre-processing steps, the model can finally train with a subset of images: 10 per class for training, and 2 per class for testing.
I also had to:
* change the generate_tfrecord.py script in **'Create TFRecords'**, to compensate for the unexpected change in order displayed in .xml bounding box co-ordinates. This should be fine now that I have specifically assigned the values xmin, ymin etc. to the names which appear in .xml classes, and not based on their position... The change in position meant that some values were wrongly assigned which resulted in negative areas.
* convert some images to JPEG format in **'Processing the pixel values to help image processing'**. These images in question were collected by me using Google, and thought none the wiser as to how formats are so deadly to Tensorflow image processing modules. It turns out a WEBP image format is not supported, so this resulted in having to convert each image to JPEG, if it wasn't in this format already. These images were collected in a smaller subset along with relevant .xml files, as this issue seemed to be a memory usage issue at the time; this is not so, at least for about 100 images.
* delete any images in the pool that didn't have an assigned .xml file in **'.XML FILES DEBUGGING'**.
                 \/ \/ \/ \/ \/ \/ \/ \/ \/ \/ \/ \/ \/ \/    
* and finally, <u>**creating multiple backups of my images**</u> <-- very important.

                 ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^

P.S. My task now is to create a precise model now, while remembering I have changed certain values in the pipeline.config file, to reflect the smaller subset of data.

# CONVERTING ORIGINAL SET OF IMAGES

Most importantly, some images contain alpha channels, and need to be universally changed to RGB format, in order to be stored as JPEG images.

Sometimes, the module imghdr will not recognise the image file extension based on the way it confirms its decisions.
```
Tensorflow/workspace/images/test/Lake_lake188.jpg is not an image
```
Using PIL and opening these images will confirm that these are indeed images

Let's try to create a model using all my training data! It's worthwhile to remember that the classes have an uneven amount of images, but this shouldn't disturb the model on first glance, as the hay-bales & humans datasets look trustworthy:
```
Class: birds, Count: 459
Class: car, Count: 363
Class: cliff, Count: 343
Class: pool, Count: 421
Class: tree, Count: 632
Class: cloud, Count: 815
Class: hay-bale, Count: 3615
Class: human, Count: 8014
Class: House, Count: 529
Class: Lake, Count: 220
```
 First, as was spotted in the smaller subset of data, I have to search for any WEBP files which Tensorflow cannot read:
"""

folder_path = "/content/drive/MyDrive/Tensorflow/workspace/images/train"

extensions = set()

for root, _, files in os.walk(folder_path):
  for file in files:
    if not file.endswith(".xml"):
      filename, extension = os.path.splitext(file)
      extensions.add(extension.lower())  # Convert to lowercase for consistency

print("File extensions not ending with '.xml':")
for ext in extensions:
  print(ext)

"""The available extensions are .jpg, .jpeg, and .png (the .db file corresponds to an automatically created 'Thumbs.db' file). Let's add these three extensions to the function below:"""

from pathlib import Path
import imghdr

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/train2"
image_extensions = [".jpg", ".png", ".jpeg"]    # my extensions

img_type_accepted_by_tf = ["bmp", "gif", "jpeg", "png"]

for filepath in Path(data_dir).rglob("*"):
  if filepath.suffix.lower() in image_extensions:
    img_type = imghdr.what(filepath)
    if img_type is None:
      print(f"{filepath} is not an image")
    elif img_type not in img_type_accepted_by_tf:
      print(f"{filepath} is a {img_type}, not accepted by TensorFlow")

"""Removing the .db file:"""

file_path = "/content/drive/MyDrive/Tensorflow/workspace/images/test/cliff_Thumbs.db"

try:
  os.remove(file_path)
  print(f"File '{file_path}' has been removed.")
except FileNotFoundError:
  print(f"File '{file_path}' not found.")
except Exception as e:
  print(f"An error occurred while trying to remove '{file_path}': {e}")

"""As expected, most of the manually sourced Google images have been marked as WEBP images. We need to convert these to JPEG format to continue with the whole training folder. I assume the testing folder also presents the same issue.

Some images contain an alpha channel along with the typical RGB colour channels. JPEG images simply use only three channels. The alpha channel is sometimes included to determine the opacity of a certain number of pixels, when placed over another image or background. When removing the alpha channel, all the pixels are fully opaque.
"""

folder_path = "/content/drive/MyDrive/Tensorflow/workspace/images/train"
for root, _, files in os.walk(folder_path):
  for file in files:
    if not file.endswith(".xml"):
      image_path = os.path.join(root, file)
      img = Image.open(image_path)

      if img.mode == "RGBA":
        print(f"Image '{file}' has an alpha channel.")

for root, _, files in os.walk(folder_path):
  for file in files:
    if not file.endswith(".xml"):
      image_path = os.path.join(root, file)
      img = Image.open(image_path)

      if img.mode == "RGBA":
        # Open the original image (without alpha channel)
        original_img = img.convert("RGB")

        # Display the images side by side
        fig, axes = plt.subplots(1, 2, figsize=(10, 5))
        axes[0].imshow(original_img)
        axes[0].set_title("Alpha channel removed")
        axes[0].axis("off")

        axes[1].imshow(img)
        axes[1].set_title("Image with Alpha Channel")
        axes[1].axis("off")

        plt.show()

"""Looking through the above images, it seems like apart from the two cloud images at the end, the result of removing the alpha channel is unnoticeable. The alpha channel is most likely present as a result of adding a slight glossy look to some of the commercial images, while others were probably added on Photoshop. It's safe to remove these when creating my converted JPEG training folder.

I must modify the function used in **Processing the pixel values to help image processing**, to convert each image to RGB first, and then convert to JPEG format.
"""

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/train"
for image_path in Path(data_dir).rglob("*"):
  print(image_path)

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/train"
for image_path in Path(data_dir).rglob("*"):
  print(image_path.stem)

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/train2"
output_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/train2_converted"
image_extensions = [".jpg", ".png", ".webp", ".jpeg"]

if not os.path.exists(output_dir):
    os.makedirs(output_dir)

for image_path in Path(data_dir).rglob("*"):
  if image_path.suffix.lower() in image_extensions:
    img_type = imghdr.what(image_path)
    if img_type is not None and img_type == "webp":
      img = Image.open(image_path)
      img = img.convert("RGB")  # Convert to RGB mode
      output_image_path = os.path.join(output_dir, image_path.name)
      img.save(output_image_path, "JPEG")
      print(f"Converted {image_path} to JPEG")

      # Find corresponding XML annotation file
      xml_filename = image_path.stem + ".xml"
      xml_path = os.path.join(data_dir, xml_filename)
      if os.path.exists(xml_path):
        output_xml_path = os.path.join(output_dir, xml_filename)
        shutil.copy(xml_path, output_xml_path)
        print(f"Copied {xml_path} to {output_xml_path}")

      else:
        output_image_path = os.path.join(output_dir, image_path.name)
        img = Image.open(image_path)
        img = img.convert("RGB")  # Convert to RGB mode
        img.save(output_image_path)
        print(f"Copying {image_path} as it is")

        # Find corresponding XML annotation file
        xml_filename = image_path.stem + ".xml"
        xml_path = os.path.join(data_dir, xml_filename)
        if os.path.exists(xml_path):
          output_xml_path = os.path.join(output_dir, xml_filename)
          shutil.copy(xml_path, output_xml_path)
          print(f"Copied {xml_path} to {output_xml_path}")

def count_images_and_annotations(folder_path):
  image_count = 0
  annotation_count = 0

  for root, dirs, files in os.walk(folder_path):
    for file in files:
      if file.lower().endswith(('.jpg', '.jpeg', '.png', '.jfif')):
        image_count += 1
      elif file.lower().endswith('.xml'):
        annotation_count += 1

  return image_count, annotation_count

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/NEWERtrain2_converted'
image_count, annotation_count = count_images_and_annotations(train_folder)

print(f"Number of image files in 'train': {image_count}")
print(f"Number of annotation files in 'train': {annotation_count}")

"""That's a converted training folder created, now it's time for the test folder to undergo the same."""

import shutil

data_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/test2"
output_dir = "/content/drive/MyDrive/Tensorflow/workspace/images/test2_converted"
image_extensions = [".jpg", ".png", ".webp", ".jpeg"]

if not os.path.exists(output_dir):
  os.makedirs(output_dir)

for image_path in Path(data_dir).rglob("*"):
  if image_path.suffix.lower() in image_extensions:
    img_type = imghdr.what(image_path)
    if img_type is not None and img_type == "webp":
      img = Image.open(image_path)
      img = img.convert("RGB")  # Convert to RGB mode
      output_image_path = os.path.join(output_dir, image_path.name)
      img.save(output_image_path, "JPEG")
      print(f"Converted {image_path} to JPEG")

      # Find corresponding XML annotation file
      xml_filename = image_path.stem + ".xml"
      xml_path = os.path.join(data_dir, xml_filename)
      if os.path.exists(xml_path):
        output_xml_path = os.path.join(output_dir, xml_filename)
        shutil.copy(xml_path, output_xml_path)
        print(f"Copied {xml_path} to {output_xml_path}")

      else:
        output_image_path = os.path.join(output_dir, image_path.name)
        img = Image.open(image_path)
        img = img.convert("RGB")  # Convert to RGB mode
        img.save(output_image_path)
        print(f"Copying {image_path} as it is")

        # Find corresponding XML annotation file
        xml_filename = image_path.stem + ".xml"
        xml_path = os.path.join(data_dir, xml_filename)
        if os.path.exists(xml_path):
          output_xml_path = os.path.join(output_dir, xml_filename)
          shutil.copy(xml_path, output_xml_path)
          print(f"Copied {xml_path} to {output_xml_path}")

def count_images_and_annotations(folder_path):
  image_count = 0
  annotation_count = 0

  for root, dirs, files in os.walk(folder_path):
    for file in files:
      if file.lower().endswith(('.jpg', '.jpeg', '.png', '.jfif')):
        image_count += 1
      elif file.lower().endswith('.xml'):
        annotation_count += 1

  return image_count, annotation_count

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/test2_converted'
image_count, annotation_count = count_images_and_annotations(train_folder)

print(f"Number of image files in 'train': {image_count}")
print(f"Number of annotation files in 'train': {annotation_count}")

"""#WRONG FINAL CHECKS ON TRAIN/TEST IMAGE FOLDERS BEFORE BIGGER MODEL"""

import os
from collections import defaultdict

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train2_converted'

class_counts = defaultdict(int)

for xml_file in os.listdir(train_folder):
  if xml_file.endswith('.xml'):
    xml_path = os.path.join(train_folder, xml_file)
    with open(xml_path, 'r') as f:
      lines = f.readlines()
      for line in lines:
        if '<name>' in line:
          class_name = line.strip().split('<name>')[1].split('</name>')[0]
          class_counts[class_name] += 1

# Print the counts for each object class
for class_name, count in class_counts.items():
  print(f"Class: {class_name}, Count: {count}")

import os
from collections import defaultdict

train_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/test2_converted'

class_counts = defaultdict(int)

for xml_file in os.listdir(train_folder):
  if xml_file.endswith('.xml'):
    xml_path = os.path.join(train_folder, xml_file)
    with open(xml_path, 'r') as f:
      lines = f.readlines()
      for line in lines:
        if '<name>' in line:
          class_name = line.strip().split('<name>')[1].split('</name>')[0]
          class_counts[class_name] += 1

# Print the counts for each object class
for class_name, count in class_counts.items():
  print(f"Class: {class_name}, Count: {count}")

"""# SECOND WARNING FOR BACKUPS

You might notice that the 'train' folder became 'train2' over the course of this converting.<br>![danger.png](data:image/png;base64,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) <br>**This shows the importance of backups!** I had to use my backup folder as I had accidentally moved the .xml files instead of copying them along with the images. Then, I went to delete the folder thinking they were just copies of the .xml files, but they were not!

# Model Evaluation
"""

command = "python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])

print(command)

!{command}

"""# Load Trained Model Checkpoint for Later use of showing predictions on images"""

import os
import tensorflow as tf
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.builders import model_builder
from object_detection.utils import config_util

# Load pipeline config and build a detection model
configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])
detection_model = model_builder.build(model_config=configs['model'], is_training=False)

# Restore checkpoint
ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)
ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-6')).expect_partial()

@tf.function
def detect_fn(image):
    image, shapes = detection_model.preprocess(image)
    prediction_dict = detection_model.predict(image, shapes)
    detections = detection_model.postprocess(prediction_dict, shapes)
    return detections

"""# Showcasing the Detection on an Image"""

# Commented out IPython magic to ensure Python compatibility.
import cv2
import numpy as np
from matplotlib import pyplot as plt
# %matplotlib inline

category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])

IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'TOPDOWNtest', 'watertp_23.jpg')

img = cv2.imread(IMAGE_PATH)
image_np = np.array(img)

input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)
detections = detect_fn(input_tensor)

num_detections = int(detections.pop('num_detections'))
detections = {key: value[0, :num_detections].numpy()
              for key, value in detections.items()}
detections['num_detections'] = num_detections

# detection_classes should be ints.
detections['detection_classes'] = detections['detection_classes'].astype(np.int64)

label_id_offset = 1
image_np_with_detections = image_np.copy()

viz_utils.visualize_boxes_and_labels_on_image_array(
            image_np_with_detections,
            detections['detection_boxes'],
            detections['detection_classes']+label_id_offset,
            detections['detection_scores'],
            category_index,
            use_normalized_coordinates=True,
            max_boxes_to_draw=10,
            min_score_thresh=.4,
            agnostic_mode=False
            )

plt.figure(figsize=(20, 16))
plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))
plt.show()

"""Images to move to training set: 'rocktp_58.jpg', 'housetp_33.jpg'

Predicting with screenshots from Tom's drone videos.
"""

import zipfile

zip_file_path = "/content/drive/MyDrive/Screenshots.zip"
extracted_folder = "/content/drive/MyDrive/drone_shots"

#with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
#    zip_ref.extractall(extracted_folder)

image_paths = [os.path.join(extracted_folder, filename) for filename in os.listdir(extracted_folder) if filename.lower().endswith(('.jpg', '.jpeg', '.png'))]

#img = cv2.imread('/content/16004597-a-shallow-tranquil-rock-strewn-river-flowing-through-lush-english-countryside-with-tree-lined.jpg')
target_size = (700, 800)  # Set the target size (width, height)

# Read the image using OpenCV
image = cv2.imread('/content/farm5.jpg')

# Resize the image
resized_image = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)

#img = cv2.imread(image_paths[10])
#image_np = np.array(img)

input_tensor = tf.convert_to_tensor(np.expand_dims(resized_image, 0), dtype=tf.float32)
detections = detect_fn(input_tensor)

num_detections = int(detections.pop('num_detections'))
detections = {key: value[0, :num_detections].numpy()
              for key, value in detections.items()}
detections['num_detections'] = num_detections

# detection_classes should be ints.
detections['detection_classes'] = detections['detection_classes'].astype(np.int64)

label_id_offset = 1
image_np_with_detections = resized_image.copy()

viz_utils.visualize_boxes_and_labels_on_image_array(
            image_np_with_detections,
            detections['detection_boxes'],
            detections['detection_classes']+label_id_offset,
            detections['detection_scores'],
            category_index,
            use_normalized_coordinates=True,
            max_boxes_to_draw=10,
            min_score_thresh=.4,
            agnostic_mode=False
            )
#%matplotlib inline
plt.figure(figsize=(10, 8))
plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
plt.figure(figsize=(15, 10))
plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))
plt.show()

"""# Evaluation of 'starting point' model with 2000 steps and batch size = 4.

The model SSD MobileNet v2 FPN-Lite 320x320 trained on COCO2017, needless to say is not a good model at all. This might be due to a number of reasons:

* I need to train it for a longer number of training steps
* The training image dataset might contain too many images.
* I need a larger model architecture to manage the large amount of images, and the 10 classes it needs to classify.

So far, my target is just to build a model that can at least classify because these results:
```
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.107
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.043
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.165
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.093
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210
 ```
 are not satisfactory at all. Results like this are useless if I need to build a patch to fool a model, and the model is unable to do its job.

# Evaluation of model with 10000 training steps and batch size 8

There's some improvement. The localisation aspect in particular looks very accurate from the test images I have detected on. The classification is still lacking in accuracy, particularly with some classes.
```
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.320
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.193
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334
 ```
 These results could still be better. The training steps should be increased and if this does not improve results sufficiently, it might be worth looking at different model architectures.

In terms of accuracy for each class, the model will be ranked by **Great**, **Sufficient**, **Bad** based on my personal opinion from testing 20 images:
<br> Birds = Bad
<br> Cars = Bad
<br> Cliffs = Bad
<br> Clouds = Bad
<br> Haybales = Great
<br> Houses = Great
<br> Lakes = Sufficient
<br> Human = Great
<br> Pools = Bad
<br> Trees = Bad
<br>
<br>Looking at these results, and also keeping the number of images available for each class:
```
Class: pool, Count: 421
Class: human, Count: 8014
Class: House, Count: 529
Class: Lake, Count: 220
Class: hay-bale, Count: 3615
Class: birds, Count: 459
Class: car, Count: 363
Class: cliff, Count: 343
Class: cloud, Count: 815
Class: tree, Count: 632
```
It is easy to see how the accuracy of detecting houses and haybales is correlated to the amount of training data available. However, this does not seem to be correct as the relatively high amount of cloud images do not ensure a good cloud detecting accuracy.
<br> Sometimes the model doesn't even predict some classes. It is unable to predict 'birds', 'trees', 'cars', 'cloud', or 'cliffs'. It is not understood why these labels are not shown to be predicted. However, the model has a high misclassification rate when attempting to label these, as it usually thinks they one of these labels: 'human', 'pool', 'haybale'.

<br> My conclusion as to arriving at a solution after these misclassification issues, is that the dataset is really imbalanced, and 'human' certainly doesn't need to have that many more images. This imbalance between classes affects the model in unforeseen ways, but  it could be unable to generalise, and to learn those smaller classes. This could be the cause for the labels which are never seen to be predicted above.
<br>Even though the high quantity classes exhibit great accuracy, there is no way I will be able to accumulate near enough images for the other classes to upscale them. Therefore, I am going to try downscaling the higher quantity classes to around 500 images.

# Deleting Pool Images

After some frustrating developments where models were retrained on less pool data, it's time to delete the pool images. The pool only appears for a split second in Tom's video, the images are all low resolution, and the images are too augmented; sometimes it's not even a pool in the image. The model should be better off as it's dealing with less data and it won't be confused by unclear localisations when it's training.
"""

pool_imgs = []
for file in os.listdir('/content/drive/MyDrive/Diss_Backups/images/train/POOLS_train'):
  pool_imgs.append(file)
print('There are:', len(pool_imgs), 'pool images')

newer_pool_imgs = []
for file in os.listdir('/content/drive/MyDrive/Tensorflow/workspace/images/NEWERtrain2_converted'):
  if file.startswith('pool'):
    newer_pool_imgs.append(file)
print('There are:', len(newer_pool_imgs), 'pool images in NEWERtrain2_converted')

start_with_pool = []
for file in os.listdir('/content/drive/MyDrive/Diss_Backups/images/train/POOLS_train'):
  if file.startswith('pool'):
    start_with_pool.append(file)

print('There are:', len(start_with_pool), 'images that start with \'pool\'')

"""```
Class: birds, Count: 444
Class: car, Count: 285
Class: cliff, Count: 189
Class: cloud, Count: 178
Class: hay-bale, Count: 867
Class: House, Count: 529
Class: Lake, Count: 150
Class: human, Count: 2192
Class: pool, Count: 416
Class: tree, Count: 173
```
"""

folder_path = '/content/drive/MyDrive/Tensorflow/workspace/images/NEWERtrain2_converted'

for filename in os.listdir(folder_path):
  if filename.startswith('pool'): #and (filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.xml')):
    file_path = os.path.join(folder_path, filename)
#    os.remove(file_path)
    print(f"Deleted: {file_path}")

"""# Removing some Human images
There are 2192 image and .xml pairs that belong to the 'human' class. This is far too much and requires some removal. The people in the drone footage are not certain to appear, and they are usually very small due to being far away. Similar to 'pool' in which it was unclear how a model was able to detect an object which appears minimally in the footage: not very well, in conclusion.
"""

human_imgs = []
for file in os.listdir('/content/drive/MyDrive/Diss_Backups/images/train/PEOPLE_train'):
  human_imgs.append(file)
print('There are:', len(human_imgs), 'human files')

newer_human_imgs = []
for file in os.listdir('/content/drive/MyDrive/Tensorflow/workspace/images/NEWERtrain2_converted'):
  if file.startswith('human'):
    newer_human_imgs.append(file)
print('There are:', len(newer_human_imgs), 'human files in NEWERtrain2_converted')

"""I would like 2192-500 = 1692 pairs of image/xml files to be deleted, to make the balance of training image classes more fair."""

folder_path = '/content/drive/MyDrive/Tensorflow/workspace/images/NEWERtrain2_converted'
file_pattern = 'human*.jpg'
delete_limit = 1962
image_files = glob.glob(os.path.join(folder_path, file_pattern))


for image_file in image_files:
  xml_file = os.path.splitext(image_file)[0] + '.xml'

  if os.path.exists(xml_file):
    os.remove(image_file)
    os.remove(xml_file)
    print(f"Deleted: {image_file} and {xml_file}")
  else:
    print(f"XML file not found for: {image_file}")

folder_path = '/content/drive/MyDrive/Tensorflow/workspace/images/test2_converted'
file_pattern = 'pool*.jpg'
delete_limit = 56

image_files = glob.glob(os.path.join(folder_path, file_pattern))

deleted_count = 0

for image_file in image_files:
  if deleted_count >= delete_limit:
    break

  xml_file = os.path.splitext(image_file)[0] + '.xml'

  if os.path.exists(xml_file):
    os.remove(image_file)
    os.remove(xml_file)
    print(f"Deleted: {image_file} and {xml_file}")
    deleted_count += 1
  else:
    print(f"XML file not found for: {image_file}")

print(f"Deleted {deleted_count} file pairs.")

os.remove('/content/drive/MyDrive/Tensorflow/workspace/images/NEWERtrain2_converted/human_img_1065_jpg.rf.86b96add9109fd9ea59c04717939dee5.jpg')

import os
import shutil

source_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train3'
destination_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/NEWERtrain2_converted'
file_pattern = 'human*.jpg'
copy_limit = 250

image_files = sorted(glob.glob(os.path.join(source_folder, file_pattern)))

copied_count = 0

for image_file in image_files:
  if copied_count >= copy_limit:
    break

  xml_file = os.path.splitext(image_file)[0] + '.xml'

  if os.path.exists(xml_file):
    destination_image = os.path.join(destination_folder, os.path.basename(image_file))
    destination_xml = os.path.join(destination_folder, os.path.basename(xml_file))

    shutil.copy(image_file, destination_image)
    shutil.copy(xml_file, destination_xml)

    print(f"Copied: {image_file} and {xml_file} to {destination_folder}")
    copied_count += 1
  else:
    print(f"XML file not found for: {image_file}")

print(f"Copied {copied_count} file pairs.")

import os
import shutil

source_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/test2_converted'
destination_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/NEWERtrain2_converted'
file_prefix = 'Lake'
move_limit = 73

image_files = [f for f in os.listdir(source_folder) if f.startswith(file_prefix) and f.endswith('.jpg')]

moved_count = 0

for image_file in image_files:
  if moved_count >= move_limit:
    break

  xml_file = os.path.splitext(image_file)[0] + '.xml'

  if os.path.exists(os.path.join(source_folder, xml_file)):
    source_image = os.path.join(source_folder, image_file)
    source_xml = os.path.join(source_folder, xml_file)

    destination_image = os.path.join(destination_folder, image_file)
    destination_xml = os.path.join(destination_folder, xml_file)

    shutil.move(source_image, destination_image)
    shutil.move(source_xml, destination_xml)

    print(f"Moved: {image_file} and {xml_file} to {destination_folder}")
    moved_count += 1
  else:
    print(f"XML file not found for: {image_file}")

print(f"Moved {moved_count} file pairs.")

"""After removing the human images and the ppol images, and acquiring a model with the same insufficient accuracy, it was clear that there was something else fundamentally wrong with my annotation/image dataset, even after trying a large selection of models.

<br> The issue, of course, was that I had seperated each class name into about 200 images, so this choice of including a certain number of examples for each class, influenced me to only annotate objects from that one class. I failed to annotate other objects from other classes that appeared in the background of any image. This had huge improvements when I created a smaller, but more possible to curate dataset, which was able to predict every class with average-to-good confidence.
"""