{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRqesuFzdfQj"
      },
      "source": [
        "This entire notebook is useful to note which problems I encountered in terms of preparing the .xml files for generating TFRecords (binary form data). However, the entire notebook was made when my dataset was faulty. I had neglected the option of annotating other objects in my images, so only houses were annotated in 'house' images, and trees in the background were left without bounding boxes. This lack of quality would confuse the model's accuracy.\n",
        "\n",
        "After I had fixed a much smaller dataset of images, and made sure to label each object I wanted to detect, the model was much more accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2U4c5df2rCb",
        "outputId": "1ce75df5-b558-4f33-ab4f-60d607596d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=0c65657d9713a4d90c14a4a34183ba0067192e0879094056e873b4b089f2f306\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWhk66cnhtbO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import wget\n",
        "import imghdr\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTGJoAhnPwi5"
      },
      "source": [
        "The first model I would like to try is the 'SSD MobileNet V2 FPNLite 320x320' model, which offers a computing speed of 22 milliseconds per frame, and an average precision of 22.2 units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-FbA6-GQZ5a"
      },
      "source": [
        "(Precision and recall are two values used to measure the validity of the model. They will be explained below when I train these models.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJEBUfjKiL_c"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'topdown'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF5sRUs-b2w7"
      },
      "source": [
        "The second model I would like to try offers a computing speed of 39 milliseconds per frame, and an average precision of 28.2 units. This model resizes the units to a larger size, 640 x 640. This model would enable the model to capture more features, so it would be worth testing out. However, overfitting could be an issue here, if a large model is asked to learn more features. Therefore, the training steps will be kept at around 10,000 - 12,500."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEjBis5VXp0A"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'thirdtry640x640'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-11C5vvgimcp"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('/content/drive/MyDrive/Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('/content/drive/MyDrive/Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
        "    'TFJS_PATH':os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH':os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH':os.path.join('/content/drive/MyDrive/Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PxlQUS5wqV6"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('/content/drive/MyDrive/Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOWSUoRAwsbw",
        "outputId": "ff6e99a3-fe3f-421b-fb16-c7bdeb4b482f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created directory: /content/drive/MyDrive/Tensorflow/workspace\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/scripts\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/models\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/workspace/annotations\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/workspace/images\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/workspace/models\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/workspace/pre-trained-models\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/workspace/models/topdown\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/workspace/models/topdown/export\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/workspace/models/topdown/tfjsexport\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/workspace/models/topdown/tfliteexport\n",
            "Created directory: /content/drive/MyDrive/Tensorflow/protoc\n"
          ]
        }
      ],
      "source": [
        "for path in paths.values():\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    print(f\"Created directory: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9O5hUwLJJBQ"
      },
      "source": [
        "# Image Moving and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5RCBGg7JLyV"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/Tensorflow/workspace/images/test/TREES_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1Psq4mpJNJ2"
      },
      "outputs": [],
      "source": [
        "# List all files in the folder\n",
        "file_list = os.listdir(folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc1SbYBtdaw5"
      },
      "source": [
        "Naming each filename according to its class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cM34YXuJMyu"
      },
      "outputs": [],
      "source": [
        "# Iterate through each file and rename with the prefix\n",
        "for filename in file_list:\n",
        "    if not filename.startswith('tree'):\n",
        "        new_filename = 'tree_' + filename\n",
        "        original_file_path = os.path.join(folder_path, filename)\n",
        "        new_file_path = os.path.join(folder_path, new_filename)\n",
        "        os.rename(original_file_path, new_file_path)\n",
        "        #print(f'Renamed: {filename} -> {new_filename}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFawuIWjWDzL"
      },
      "source": [
        "I need to update the .xml files for each image now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU_Y5iMPWDb9"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/Tensorflow/workspace/images'\n",
        "subfolders = ['train', 'test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2Z6a67CWMgl"
      },
      "outputs": [],
      "source": [
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(base_dir, subfolder)\n",
        "    #for root, dirs, files in os.walk(subfolder_path):\n",
        "    for xml_file in glob.glob(subfolder_path + '/*.xml'):\n",
        "          tree = ET.parse(xml_file)\n",
        "          root = tree.getroot()\n",
        "\n",
        "          # Extract the filename from the XML file\n",
        "          xml_filename = os.path.basename(xml_file).replace('.xml', '') + '.jpg'\n",
        "\n",
        "          # Update the <filename> element\n",
        "          filename_element = root.find('filename')\n",
        "          if filename_element is not None:\n",
        "            filename_element.text = xml_filename\n",
        "\n",
        "          path_element = root.find('path')\n",
        "          if path_element is not None:\n",
        "            new_path = os.path.join(subfolder, xml_filename)\n",
        "            path_element.text = new_path\n",
        "\n",
        "          # Save the changes back to the XML file\n",
        "          tree.write(xml_file)\n",
        "          #print(f\"Updated {xml_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuJihgD5fQ5E"
      },
      "outputs": [],
      "source": [
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(base_dir, subfolder)\n",
        "    for xml_file in glob.glob(subfolder_path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Extract the filename from the XML file\n",
        "        xml_filename = os.path.basename(xml_file).replace('.xml', '')\n",
        "\n",
        "        # Find the corresponding image file\n",
        "        image_extensions = ['.jpg', '.jpeg', '.png', '.jfif']  # Add other possible extensions\n",
        "        image_file = None\n",
        "        for ext in image_extensions:\n",
        "            image_path = os.path.join(subfolder_path, xml_filename + ext)\n",
        "            if os.path.exists(image_path):\n",
        "                image_file = xml_filename + ext\n",
        "                break\n",
        "\n",
        "        if image_file is not None:\n",
        "            # Update the <filename> element\n",
        "            filename_element = root.find('filename')\n",
        "            if filename_element is not None:\n",
        "                filename_element.text = image_file\n",
        "\n",
        "            # Update the <path> element\n",
        "            path_element = root.find('path')\n",
        "            if path_element is not None:\n",
        "                new_path = os.path.join(subfolder, image_file)\n",
        "                path_element.text = new_path\n",
        "\n",
        "            # Save the changes back to the XML file\n",
        "            tree.write(xml_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQme4q_VZ2gX"
      },
      "source": [
        "Extracting the images into the 'train', and 'test' folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFaCG6v0Z1bL"
      },
      "outputs": [],
      "source": [
        "source_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train/TREES_train'\n",
        "destination_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd5ZlNBMZw5O",
        "outputId": "c84e3984-4939-4ab1-8b8d-ae03a6193b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files moved successfully!\n"
          ]
        }
      ],
      "source": [
        "for filename in os.listdir(source_folder):\n",
        "  source_path = os.path.join(source_folder, filename)\n",
        "  destination_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "  # Move the file to the destination folder\n",
        "  shutil.move(source_path, destination_path)\n",
        "\n",
        "print(\"Files moved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4h3LQgx20Ft"
      },
      "source": [
        "# Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD\n",
        "\n",
        "only need to do this ONCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z1ki9Jq21N9",
        "outputId": "1fbe21b9-5ef8-4983-8900-eb412f9fdf64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '/content/drive/MyDrive/Tensorflow/models'...\n",
            "remote: Enumerating objects: 87125, done.\u001b[K\n",
            "remote: Counting objects: 100% (879/879), done.\u001b[K\n",
            "remote: Compressing objects: 100% (403/403), done.\u001b[K\n",
            "remote: Total 87125 (delta 522), reused 792 (delta 468), pack-reused 86246\u001b[K\n",
            "Receiving objects: 100% (87125/87125), 599.11 MiB | 18.17 MiB/s, done.\n",
            "Resolving deltas: 100% (62396/62396), done.\n",
            "Updating files: 100% (3563/3563), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGZN7yQ35Yvs",
        "outputId": "ad9c4ed1-4fcd-4d62-a673-c9d0e84e600d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "Processing /content/drive/MyDrive/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object-detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object-detection==0.1)\n",
            "  Downloading apache_beam-2.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.29.36)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n",
            "Collecting lvis (from object-detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n",
            "  Downloading tf_models_official-2.13.1-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n",
            "  Downloading tensorflow_io-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.12.0)\n",
            "Collecting pyparsing==2.4.7 (from object-detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0 (from object-detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.5)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Collecting pyyaml<5.4.0,>=5.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.14.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.13.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.13.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.3)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading orjson-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.57.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading hdfs-2.7.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pymongo-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.3/671.3 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.22.3)\n",
            "Requirement already satisfied: protobuf<4.24.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.7.1)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.42.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (23.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.33.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.33.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.7.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n",
            "Collecting keras (from object-detection==0.1)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n",
            "Collecting typing-extensions>=3.7.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.41.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.16.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, pyyaml, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697179 sha256=76b519e511bad63ac6b17391cd9cbce0cd953b758a629a3842f2bc53eb705700\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-90ryaxxe/wheels/d9/8d/40/99c550dc0e9c3cb6a35f54fa15aebb562f3ca108579f3b1637\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43991 sha256=2dc726592145ed6d9c6637d304c96a495d413a650236f6fdae40f56f2ba93f67\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31403 sha256=410e993b20d760d8433f0dc06422788a47ff44ed409aa891defd3c2fc3fca1da\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=1684c93762e7987f21ba89fcbaefbe759775f372c1a91b85945813583ce1d222\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.2-py3-none-any.whl size=34168 sha256=52fc69a914a7e8997f686785d249bd3b2db3b12090c79efd1e70860db0e43354\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/39/8e/e1905de9af8ae74911cd3e53e721995cd230816f63776e5825\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp310-cp310-linux_x86_64.whl size=44635 sha256=5e4bb07093662e2cd8432149762818debadbe5f42fa4d43d9864daf94e57a6f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/a9/6a/d0a6981a8dbb698845178818642f72ce179f14336908c7df01\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=fe4ab31072be3fb83d00ef99d30e64dbac5d24efa80fdfe93c30f276ac7bde9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=3754923b330d1e793c2b614cca7ceb0e633f9d02c4d28702b10cf85443299dd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object-detection avro-python3 crcmod dill hdfs pyyaml seqeval docopt\n",
            "Installing collected packages: sentencepiece, docopt, crcmod, zstandard, typing-extensions, tensorflow-model-optimization, tensorflow_io, tensorflow-estimator, pyyaml, pyparsing, portalocker, orjson, objsize, keras, immutabledict, fasteners, fastavro, dnspython, dill, colorama, avro-python3, sacrebleu, pymongo, hdfs, seqeval, lvis, apache-beam, tensorboard, tensorflow, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.7.2 requires PyYAML>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\n",
            "pydantic 2.2.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.6.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.49.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.8.2 fasteners-0.18 hdfs-2.7.2 immutabledict-3.0.0 keras-2.13.1 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.9.5 portalocker-2.7.0 pymongo-4.5.0 pyparsing-2.4.7 pyyaml-5.3.1 sacrebleu-2.2.0 sentencepiece-0.1.99 seqeval-1.2.2 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.13.0 tensorflow_io-0.33.0 tf-models-official-2.13.1 typing-extensions-4.5.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "!apt-get install protobuf-compiler\n",
        "!cd /content/drive/MyDrive/Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewAXC3UKesdR"
      },
      "source": [
        "Run the above code at the start of each runtime, then run the following cell to import all the necessary modules in the environment. Colab creates a new environment automatically, but actions in Command Prompt will need a new environment created for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_32tFwTAhT-",
        "outputId": "a5d69f98-e379-4be6-d996-ba341c99fd4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-28 08:23:18.903537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-28 08:23:19.878388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-28 08:23:22.849133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-28 08:23:23.395765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-28 08:23:23.396103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2023-08-28 08:23:23.404041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-28 08:23:23.404296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-28 08:23:23.404503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-28 08:23:24.434934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-28 08:23:24.435234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-28 08:23:24.435406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-28 08:23:24.435523: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-08-28 08:23:24.435558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13692 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0828 08:23:24.628570 135763593556608 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0828 08:23:24.902250 135763593556608 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.81s\n",
            "I0828 08:23:25.208187 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.81s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "I0828 08:23:25.779669 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.32s\n",
            "I0828 08:23:26.095918 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.32s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.45s\n",
            "I0828 08:23:26.545428 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.45s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.03s\n",
            "I0828 08:23:28.571465 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0828 08:23:28.578312 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0828 08:23:28.605612 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0828 08:23:28.623219 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0828 08:23:28.641244 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "I0828 08:23:28.747426 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
            "I0828 08:23:28.849576 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "I0828 08:23:28.955701 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "I0828 08:23:29.062240 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "I0828 08:23:29.165305 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0828 08:23:29.197179 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0828 08:23:29.389367 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0828 08:23:29.389521 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I0828 08:23:29.389573 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
            "I0828 08:23:29.392153 135763593556608 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0828 08:23:29.421011 135763593556608 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0828 08:23:29.421149 135763593556608 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0828 08:23:29.499401 135763593556608 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0828 08:23:29.499560 135763593556608 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0828 08:23:29.700532 135763593556608 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0828 08:23:29.700711 135763593556608 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0828 08:23:29.889356 135763593556608 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0828 08:23:29.889516 135763593556608 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0828 08:23:30.166555 135763593556608 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0828 08:23:30.166713 135763593556608 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0828 08:23:30.447125 135763593556608 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0828 08:23:30.447288 135763593556608 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0828 08:23:30.811300 135763593556608 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0828 08:23:30.811451 135763593556608 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0828 08:23:30.899705 135763593556608 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0828 08:23:30.943365 135763593556608 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0828 08:23:30.998191 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0828 08:23:30.998341 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I0828 08:23:30.998386 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
            "I0828 08:23:31.000219 135763593556608 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0828 08:23:31.018962 135763593556608 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0828 08:23:31.019068 135763593556608 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0828 08:23:31.165658 135763593556608 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0828 08:23:31.165806 135763593556608 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0828 08:23:31.431240 135763593556608 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0828 08:23:31.431388 135763593556608 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0828 08:23:31.696778 135763593556608 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0828 08:23:31.696926 135763593556608 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0828 08:23:32.265043 135763593556608 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0828 08:23:32.265193 135763593556608 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0828 08:23:32.615338 135763593556608 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0828 08:23:32.615492 135763593556608 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0828 08:23:33.058749 135763593556608 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0828 08:23:33.058896 135763593556608 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0828 08:23:33.240753 135763593556608 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0828 08:23:33.274326 135763593556608 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0828 08:23:33.338022 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0828 08:23:33.338176 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I0828 08:23:33.338221 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
            "I0828 08:23:33.340043 135763593556608 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0828 08:23:33.358611 135763593556608 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0828 08:23:33.358723 135763593556608 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0828 08:23:33.496416 135763593556608 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0828 08:23:33.496582 135763593556608 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0828 08:23:33.764225 135763593556608 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0828 08:23:33.764378 135763593556608 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0828 08:23:34.040246 135763593556608 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0828 08:23:34.040398 135763593556608 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0828 08:23:34.408891 135763593556608 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0828 08:23:34.409066 135763593556608 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0828 08:23:34.782694 135763593556608 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0828 08:23:34.782844 135763593556608 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0828 08:23:35.250539 135763593556608 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0828 08:23:35.250705 135763593556608 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0828 08:23:35.441942 135763593556608 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0828 08:23:35.479756 135763593556608 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0828 08:23:35.543313 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0828 08:23:35.543458 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I0828 08:23:35.543515 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
            "I0828 08:23:35.545341 135763593556608 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0828 08:23:35.566107 135763593556608 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0828 08:23:35.566235 135763593556608 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0828 08:23:35.723639 135763593556608 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0828 08:23:35.723795 135763593556608 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0828 08:23:36.000910 135763593556608 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0828 08:23:36.001069 135763593556608 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0828 08:23:36.275628 135763593556608 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0828 08:23:36.275777 135763593556608 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0828 08:23:36.734692 135763593556608 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0828 08:23:36.734843 135763593556608 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0828 08:23:37.202777 135763593556608 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0828 08:23:37.202926 135763593556608 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0828 08:23:37.765931 135763593556608 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0828 08:23:37.766087 135763593556608 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0828 08:23:37.977839 135763593556608 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0828 08:23:38.020066 135763593556608 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0828 08:23:38.092318 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0828 08:23:38.092471 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I0828 08:23:38.092530 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0828 08:23:38.094472 135763593556608 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0828 08:23:38.116662 135763593556608 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0828 08:23:38.116777 135763593556608 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0828 08:23:38.272918 135763593556608 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0828 08:23:38.273100 135763593556608 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0828 08:23:38.646031 135763593556608 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0828 08:23:38.646191 135763593556608 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0828 08:23:39.025626 135763593556608 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0828 08:23:39.025785 135763593556608 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0828 08:23:39.849044 135763593556608 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0828 08:23:39.849199 135763593556608 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0828 08:23:40.413676 135763593556608 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0828 08:23:40.413826 135763593556608 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0828 08:23:41.175240 135763593556608 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0828 08:23:41.175391 135763593556608 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0828 08:23:41.365797 135763593556608 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0828 08:23:41.404073 135763593556608 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0828 08:23:41.483816 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0828 08:23:41.483964 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I0828 08:23:41.484013 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
            "I0828 08:23:41.485939 135763593556608 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0828 08:23:41.504698 135763593556608 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0828 08:23:41.504825 135763593556608 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0828 08:23:41.726903 135763593556608 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0828 08:23:41.727065 135763593556608 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0828 08:23:42.181711 135763593556608 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0828 08:23:42.181862 135763593556608 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0828 08:23:42.640348 135763593556608 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0828 08:23:42.640498 135763593556608 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0828 08:23:43.284542 135763593556608 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0828 08:23:43.284706 135763593556608 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0828 08:23:43.925127 135763593556608 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0828 08:23:43.925275 135763593556608 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0828 08:23:44.740480 135763593556608 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0828 08:23:44.740644 135763593556608 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0828 08:23:45.029332 135763593556608 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0828 08:23:45.067503 135763593556608 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0828 08:23:45.158182 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0828 08:23:45.158337 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0828 08:23:45.158382 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0828 08:23:45.160204 135763593556608 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0828 08:23:45.180854 135763593556608 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0828 08:23:45.180956 135763593556608 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0828 08:23:45.401974 135763593556608 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0828 08:23:45.402123 135763593556608 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0828 08:23:45.944180 135763593556608 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0828 08:23:45.944335 135763593556608 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0828 08:23:46.497811 135763593556608 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0828 08:23:46.497963 135763593556608 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0828 08:23:47.232961 135763593556608 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0828 08:23:47.233123 135763593556608 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0828 08:23:48.284553 135763593556608 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0828 08:23:48.284717 135763593556608 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0828 08:23:49.288640 135763593556608 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0828 08:23:49.288790 135763593556608 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0828 08:23:49.565653 135763593556608 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0828 08:23:49.604831 135763593556608 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0828 08:23:49.706559 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0828 08:23:49.706720 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I0828 08:23:49.706770 135763593556608 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
            "I0828 08:23:49.708615 135763593556608 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0828 08:23:49.729225 135763593556608 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0828 08:23:49.729356 135763593556608 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0828 08:23:50.023663 135763593556608 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0828 08:23:50.023816 135763593556608 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0828 08:23:50.652199 135763593556608 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0828 08:23:50.652347 135763593556608 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0828 08:23:51.276514 135763593556608 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0828 08:23:51.276692 135763593556608 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0828 08:23:52.176091 135763593556608 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0828 08:23:52.176245 135763593556608 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0828 08:23:53.071645 135763593556608 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0828 08:23:53.071812 135763593556608 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0828 08:23:54.276309 135763593556608 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0828 08:23:54.276466 135763593556608 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0828 08:23:54.660302 135763593556608 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0828 08:23:54.702505 135763593556608 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 25.63s\n",
            "I0828 08:23:54.823047 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 25.63s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0828 08:23:54.851859 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0828 08:23:54.853656 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0828 08:23:54.854108 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0828 08:23:54.855432 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0828 08:23:54.856667 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0828 08:23:54.857038 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0828 08:23:54.857956 135763593556608 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 31.459s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUrNUN9wC8vu"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNIYgYbXDDR3",
        "outputId": "f64e1f32-0007-4184-ebaa-166ac279fd87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.8.5\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.13\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.5.0\n",
            "anyio                            3.7.1\n",
            "apache-beam                      2.49.0\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      21.3.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array-record                     0.4.1\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.1\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "attrs                            23.1.0\n",
            "audioread                        3.0.0\n",
            "autograd                         1.6.2\n",
            "avro-python3                     1.10.2\n",
            "Babel                            2.12.1\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.11.2\n",
            "bleach                           6.0.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.10\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.2.2\n",
            "branca                           0.6.0\n",
            "build                            0.10.0\n",
            "CacheControl                     0.13.1\n",
            "cachetools                       5.3.1\n",
            "catalogue                        2.0.9\n",
            "certifi                          2023.7.22\n",
            "cffi                             1.15.1\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.2.0\n",
            "chex                             0.1.7\n",
            "click                            8.1.6\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.2\n",
            "cmdstanpy                        1.1.0\n",
            "colorama                         0.4.6\n",
            "colorcet                         3.0.1\n",
            "colorlover                       0.3.0\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.1\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.1.0\n",
            "convertdate                      2.4.0\n",
            "crcmod                           1.7\n",
            "cryptography                     41.0.3\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda11x                     11.0.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.2\n",
            "cycler                           0.11.0\n",
            "cymem                            2.0.7\n",
            "Cython                           0.29.36\n",
            "dask                             2023.8.0\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.1.1\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "dill                             0.3.1.1\n",
            "distributed                      2023.8.0\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "dnspython                        2.4.2\n",
            "docopt                           0.6.2\n",
            "docutils                         0.18.1\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.8.1\n",
            "earthengine-api                  0.1.363\n",
            "easydict                         1.10\n",
            "ecos                             2.0.12\n",
            "editdistance                     0.6.2\n",
            "en-core-web-sm                   3.6.0\n",
            "entrypoints                      0.4\n",
            "ephem                            4.1.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.4.1\n",
            "etuples                          0.3.9\n",
            "exceptiongroup                   1.1.2\n",
            "fastai                           2.7.12\n",
            "fastavro                         1.8.2\n",
            "fastcore                         1.5.29\n",
            "fastdownload                     0.0.7\n",
            "fasteners                        0.18\n",
            "fastjsonschema                   2.18.0\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.1\n",
            "filelock                         3.12.2\n",
            "Fiona                            1.9.4.post1\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      23.5.26\n",
            "flax                             0.7.2\n",
            "folium                           0.14.0\n",
            "fonttools                        4.42.0\n",
            "frozendict                       2.3.8\n",
            "frozenlist                       1.4.0\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.4.0\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.4.3\n",
            "gdown                            4.6.6\n",
            "gensim                           4.3.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.17.3\n",
            "google-auth-httplib2             0.1.0\n",
            "google-auth-oauthlib             1.0.0\n",
            "google-cloud-bigquery            3.10.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.22.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.2\n",
            "google-cloud-language            2.9.1\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.5.0\n",
            "googleapis-common-protos         1.60.0\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.1\n",
            "greenlet                         2.0.2\n",
            "grpc-google-iam-v1               0.12.6\n",
            "grpcio                           1.57.0\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          3.4.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.2.0\n",
            "h5py                             3.9.0\n",
            "hdfs                             2.7.2\n",
            "holidays                         0.30\n",
            "holoviews                        1.17.0\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "idna                             3.4\n",
            "imageio                          2.31.1\n",
            "imageio-ffmpeg                   0.4.8\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "immutabledict                    3.0.0\n",
            "importlib-metadata               6.8.0\n",
            "importlib-resources              6.0.1\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "intel-openmp                     2023.2.0\n",
            "ipykernel                        5.5.6\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.1.2\n",
            "jax                              0.4.14\n",
            "jaxlib                           0.4.14+cuda11.cudnn86\n",
            "jeepney                          0.7.1\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.2\n",
            "joblib                           1.3.2\n",
            "jsonpickle                       3.0.2\n",
            "jsonschema                       4.19.0\n",
            "jsonschema-specifications        2023.7.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.3.1\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab-pygments              0.2.2\n",
            "jupyterlab-widgets               3.0.8\n",
            "kaggle                           1.5.16\n",
            "keras                            2.13.1\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.4\n",
            "langcodes                        3.3.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.3\n",
            "libclang                         16.0.6\n",
            "librosa                          0.10.0.post2\n",
            "lightgbm                         4.0.0\n",
            "linkify-it-py                    2.0.2\n",
            "lit                              16.0.6\n",
            "llvmlite                         0.39.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "LunarCalendar                    0.0.9\n",
            "lvis                             0.5.3\n",
            "lxml                             4.9.3\n",
            "Markdown                         3.4.4\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.3\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.6\n",
            "matplotlib-venn                  0.11.9\n",
            "mdit-py-plugins                  0.4.0\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.2\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.5\n",
            "multidict                        6.0.4\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.9\n",
            "music21                          9.1.0\n",
            "natsort                          8.4.0\n",
            "nbclient                         0.8.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.9.2\n",
            "nest-asyncio                     1.5.7\n",
            "networkx                         3.1\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.4.8\n",
            "numba                            0.56.4\n",
            "numexpr                          2.8.5\n",
            "numpy                            1.23.5\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "object-detection                 0.1\n",
            "objsize                          0.6.1\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.8.0.76\n",
            "openpyxl                         3.1.2\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.1.7\n",
            "orbax-checkpoint                 0.3.2\n",
            "orjson                           3.9.5\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        23.1\n",
            "pandas                           1.5.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.17.9\n",
            "pandocfilters                    1.5.0\n",
            "panel                            1.2.1\n",
            "param                            1.13.0\n",
            "parso                            0.8.3\n",
            "partd                            1.4.0\n",
            "pathlib                          1.0.1\n",
            "pathy                            0.10.2\n",
            "patsy                            0.5.3\n",
            "pexpect                          4.8.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     3.10.0\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.2\n",
            "pluggy                           1.2.0\n",
            "polars                           0.17.3\n",
            "pooch                            1.6.0\n",
            "portalocker                      2.7.0\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.8\n",
            "prettytable                      3.8.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus-client                0.17.1\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.39\n",
            "prophet                          1.1.4\n",
            "proto-plus                       1.22.3\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.7\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          9.0.0\n",
            "pyasn1                           0.5.0\n",
            "pyasn1-modules                   0.3.0\n",
            "pycocotools                      2.0.6\n",
            "pycparser                        2.21\n",
            "pyct                             0.5.0\n",
            "pydantic                         2.1.1\n",
            "pydantic_core                    2.4.0\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.0.3\n",
            "pygame                           2.5.0\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.7.2\n",
            "PyMeeus                          0.5.12\n",
            "pymongo                          4.4.1\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        23.2.0\n",
            "pyparsing                        2.4.7\n",
            "pyproj                           3.6.0\n",
            "pyproject_hooks                  1.0.0\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.14.2\n",
            "pytest                           7.4.0\n",
            "python-apt                       0.0.0\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.1\n",
            "python-utils                     3.7.0\n",
            "pytz                             2023.3\n",
            "pyviz-comms                      2.3.2\n",
            "PyWavelets                       1.4.1\n",
            "PyYAML                           5.3.1\n",
            "pyzmq                            23.2.1\n",
            "qdldl                            0.1.7.post0\n",
            "qudida                           0.0.4\n",
            "referencing                      0.30.2\n",
            "regex                            2023.6.3\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.5.0\n",
            "rich                             13.5.2\n",
            "rpds-py                          0.9.2\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "sacrebleu                        2.2.0\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.10.1\n",
            "scs                              3.2.3\n",
            "seaborn                          0.12.2\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.2\n",
            "sentencepiece                    0.1.99\n",
            "seqeval                          1.2.2\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.1\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.3.0\n",
            "sniffio                          1.3.0\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.4.1\n",
            "soxr                             0.3.5\n",
            "spacy                            3.6.1\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.4\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.6\n",
            "sphinxcontrib-devhelp            1.0.4\n",
            "sphinxcontrib-htmlhelp           2.0.3\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.5\n",
            "sphinxcontrib-serializinghtml    1.1.7\n",
            "SQLAlchemy                       2.0.19\n",
            "sqlparse                         0.4.4\n",
            "srsly                            2.4.7\n",
            "statsmodels                      0.14.0\n",
            "sympy                            1.12\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.10.0\n",
            "tblib                            2.0.0\n",
            "tenacity                         8.2.2\n",
            "tensorboard                      2.13.0\n",
            "tensorboard-data-server          0.7.1\n",
            "tensorflow                       2.13.0\n",
            "tensorflow-datasets              4.9.2\n",
            "tensorflow-estimator             2.13.0\n",
            "tensorflow-gcs-config            2.12.0\n",
            "tensorflow-hub                   0.14.0\n",
            "tensorflow-io                    0.33.0\n",
            "tensorflow-io-gcs-filesystem     0.33.0\n",
            "tensorflow-metadata              1.14.0\n",
            "tensorflow-model-optimization    0.7.5\n",
            "tensorflow-probability           0.20.1\n",
            "tensorflow-text                  2.13.0\n",
            "tensorstore                      0.1.41\n",
            "termcolor                        2.3.0\n",
            "terminado                        0.17.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf-models-official               2.13.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.1.12\n",
            "threadpoolctl                    3.2.0\n",
            "tifffile                         2023.8.12\n",
            "tinycss2                         1.2.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.0\n",
            "torch                            2.0.1+cu118\n",
            "torchaudio                       2.0.2+cu118\n",
            "torchdata                        0.6.1\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.15.2\n",
            "torchvision                      0.15.2+cu118\n",
            "tornado                          6.3.1\n",
            "tqdm                             4.66.1\n",
            "traitlets                        5.7.1\n",
            "triton                           2.0.0\n",
            "tweepy                           4.13.0\n",
            "typer                            0.9.0\n",
            "types-setuptools                 68.0.0.3\n",
            "typing_extensions                4.5.0\n",
            "tzlocal                          5.0.1\n",
            "uc-micro-py                      1.0.2\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.4\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.6\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.6.1\n",
            "Werkzeug                         2.3.6\n",
            "wget                             3.2\n",
            "wheel                            0.41.1\n",
            "widgetsnbextension               3.6.5\n",
            "wordcloud                        1.9.2\n",
            "wrapt                            1.14.1\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.6.0\n",
            "xgboost                          1.7.6\n",
            "xlrd                             2.0.1\n",
            "xyzservices                      2023.7.0\n",
            "yarl                             1.9.2\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.28\n",
            "zict                             3.0.0\n",
            "zipp                             3.16.2\n",
            "zstandard                        0.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG6t-YR6e_6O"
      },
      "source": [
        "This cell downloads the pre-trained model you named as PRETRAINED_MODEL_NAME where PRETRAINED_MODEL_URL is available to pick from the list at https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3F50BMIE1lv",
        "outputId": "a2b02959-4b6c-4e13-96a6-3118f5eacd88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "!wget {PRETRAINED_MODEL_URL}\n",
        "!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "#!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtgamhafPyjM"
      },
      "outputs": [],
      "source": [
        "PRETRAINED_MODEL_NAME = '/content/drive/MyDrive/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLD0cepVPKoR",
        "outputId": "53179d27-805f-48ee-8f4b-49acaae8c941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./\n",
            "./saved_model.pb\n",
            "./variables/\n",
            "./variables/variables.data-00000-of-00001\n",
            "./variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "#!wget {PRETRAINED_MODEL_URL}\n",
        "#!mv {PRETRAINED_MODEL_NAME} {paths['PRETRAINED_MODEL_PATH']}\n",
        "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGHnig5XVj6N"
      },
      "source": [
        "# backup folder for object detection image set\n",
        "<br> ![danger.png](data:image/png;base64,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)\n",
        "<br> <u>**Backups are so important to have!!!**</u>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7BjbH9WJVoSJ",
        "outputId": "f85b7787-c3ac-4e8e-c815-c93f15eca569"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Tensorflow/workspace/images/train3_converted'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "source_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train2_converted'\n",
        "backup_folder = '/content/drive/MyDrive/Tensorflow/workspace/images/train3_converted'\n",
        "\n",
        "# Create a backup of the source folder\n",
        "shutil.copytree(source_folder, backup_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px6KuQNgRt6Z"
      },
      "source": [
        "# CREATE LABEL MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOtTs1CAS401"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b01NXsDQhkH2"
      },
      "source": [
        "The following functions are made to check the .xml files are all present for each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXe6s-QJaTFW"
      },
      "outputs": [],
      "source": [
        "def extract_labels(xml_file_path):\n",
        "  labels = []\n",
        "\n",
        "  tree = ET.parse(xml_file_path)\n",
        "  root = tree.getroot()\n",
        "\n",
        "  for obj in root.findall('object'):\n",
        "    name = obj.find('name')\n",
        "    if name is not None:\n",
        "      labels.append(name.text)\n",
        "\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTiKBTxTaVNS"
      },
      "outputs": [],
      "source": [
        "def get_unique_labels(folder_path):\n",
        "  all_labels = []\n",
        "\n",
        "  for xml_filename in os.listdir(folder_path):\n",
        "    if xml_filename.endswith('.xml'):\n",
        "      xml_path = os.path.join(folder_path, xml_filename)\n",
        "      labels = extract_labels(xml_path)\n",
        "      all_labels.extend(labels)\n",
        "\n",
        "  unique_labels = list(set(all_labels))\n",
        "  return unique_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wg_jOaRSQKY"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/OBJ_DETECTION_IMGS/TREES_OBJDET/test'\n",
        "unique_labels = get_unique_labels(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJb5C1ooapYN",
        "outputId": "21ed7e93-2821-4466-f168-53f9c48436d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique labels found in the XML files:\n",
            "tree\n"
          ]
        }
      ],
      "source": [
        "print(\"Unique labels found in the XML files:\")\n",
        "for label in unique_labels:\n",
        "  print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rOBupfgZNin",
        "outputId": "caf79be5-9245-4b88-e479-f8458e71d8b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels found in XML files:\n",
            "['car', 'sheep', 'person', 'vegetation', 'rock', 'house', 'water']\n"
          ]
        }
      ],
      "source": [
        "xml_dir = \"/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtrain\"\n",
        "labels = set()\n",
        "\n",
        "# Loop through XML files in the directory\n",
        "for xml_file in os.listdir(xml_dir):\n",
        "  if xml_file.endswith('.xml'):\n",
        "    xml_path = os.path.join(xml_dir, xml_file)\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "      label = obj.find('name').text\n",
        "      labels.add(label)\n",
        "\n",
        "label_list = list(labels)\n",
        "print(\"Labels found in XML files:\")\n",
        "print(label_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNBHZWwgRvwS"
      },
      "outputs": [],
      "source": [
        "#labels = [{'name':'birds', 'id':1}, {'name':'car', 'id':2}, {'name':'cliff', 'id':3}, {'name':'cloud', 'id':4}, {'name':'hay-bale', 'id':5}, {'name':'House', 'id':6}, {'name':'Lake', 'id':7}, {'name':'human', 'id':8}, {'name':'tree', 'id':9}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "  for label in labels:\n",
        "    f.write('item { \\n')\n",
        "    f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "    f.write('\\tid:{}\\n'.format(label['id']))\n",
        "    f.write('}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJRcQNsXZjRZ"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'car', 'id':1}, {'name':'house', 'id':2}, {'name':'person', 'id':3}, {'name':'rock', 'id':4}, {'name':'sheep', 'id':5}, {'name':'vegetation', 'id':6}, {'name':'water', 'id':7}]\n",
        "#with open(files['LABELMAP'], 'w') as f:\n",
        "#  for label in labels:\n",
        "#     f.write('item { \\n')\n",
        "#     f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "#     f.write('\\tid:{}\\n'.format(label['id']))\n",
        "#     f.write('}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFbyLMg4PvRZ"
      },
      "outputs": [],
      "source": [
        "image_folder = ['/content/drive/MyDrive/Tensorflow/workspace/images/TOPDOWNtest']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8Yu4tWg3Q7q"
      },
      "outputs": [],
      "source": [
        "for folder in image_folder:\n",
        "  for root, dirs, files in os.walk(folder):\n",
        "    for file in files:\n",
        "      if file.lower().endswith(('.jpg', '.png', '.jfif', '.jpeg')):\n",
        "        image_path = os.path.join(root, file)\n",
        "        try:\n",
        "          img = Image.open(image_path)\n",
        "        except Exception as e:\n",
        "          print(f\"Error processing image: {image_path}\")\n",
        "          print(f\"Error message: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfx5EX8OPtPx",
        "outputId": "9f0ba4c7-caa4-4966-8bd1-834343406595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing image: /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake3.jpg\n",
            "Error message: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage]\n",
            "Error processing image: /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake115.jpg\n",
            "Error message: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage]\n",
            "Error processing image: /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake67.jpg\n",
            "Error message: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage]\n",
            "Error processing image: /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake136.jpg\n",
            "Error message: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage]\n",
            "Error processing image: /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake129.jpg\n",
            "Error message: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage]\n"
          ]
        }
      ],
      "source": [
        "for folder in image_folder:\n",
        "  for root, dirs, files in os.walk(folder):\n",
        "    for file in files:\n",
        "      if not file.lower().endswith('.xml'):\n",
        "        image_path = os.path.join(root, file)\n",
        "        try:\n",
        "          # Use TensorFlow to load the image\n",
        "          img_raw = tf.io.read_file(image_path)\n",
        "          img = tf.image.decode_image(img_raw)\n",
        "\n",
        "        except Exception as e:\n",
        "          print(f\"Error processing image: {image_path}\")\n",
        "          print(f\"Error message: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ULZt9MlLqZ0"
      },
      "source": [
        "Some images cannot be processed by the Tensorflow image processing module. This seems to be a common problem when using images collected from Google. They are all .jpg files so the error doesn't really help:\n",
        "```\n",
        "<br>Error processing image: /content/drive/MyDrive/Tensorflow/workspace/images/train_small/Lake_lake3.jpg\n",
        "Error message: {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeImage] name:\n",
        "\n",
        "```\n",
        "It could be worth analysing the images to see if some outlying pixel values are causing the issue.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "e9O5hUwLJJBQ",
        "g4h3LQgx20Ft",
        "gGHnig5XVj6N",
        "Px6KuQNgRt6Z",
        "HJOZ9t4aMb10",
        "kPxN2Q7gKxix",
        "TJQ7l3Mw-kdN"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
